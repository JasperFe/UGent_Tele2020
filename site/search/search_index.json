{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Teledetectie Practica 2020 Welkom bij de cursussite voor de practica van Teledetectie 2020. Doorheen de practica wordt deze site aangevuld met nieuwe documentatie, extra informatie en FAQ's. Remote Sensing | Spatial Analysis lab (REMOSA)","title":"Home"},{"location":"index.html#teledetectie-practica-2020","text":"Welkom bij de cursussite voor de practica van Teledetectie 2020. Doorheen de practica wordt deze site aangevuld met nieuwe documentatie, extra informatie en FAQ's. Remote Sensing | Spatial Analysis lab (REMOSA)","title":"Teledetectie Practica 2020"},{"location":"P3-Sentinel2.html","text":"The ESA Copernicus programme Copernicus is the EU's Earth Observation Programme, looking at our planet and its environment for the ultimate benefit of all European citizens. The overall goal is achieving a global, continuous, autonomous, high quality, wide range Earth observation capacity. Under the copernicus programme, ESA is developing a series of next-generation Earth observation missions under the name of 'Sentinel' programme. This Sentinel Programme, consists of multiple satellites, each focussing on a different aspect of Earth observation: atmospheric, Oceanic and Land monitoring: Current Sentinel satellites, with their main goal. (Source: ESA) In this practical will focus on the multispectral imagery taken by Sentinel 2 satellites. The Sentinel-2 mission Sentinel-2 is the copernicus Earth observation mission by ESA with the goal to perform terrestrial observations in support of services such as forest monitoring, land cover changes detection, and natural disaster management. It consists of two identical satellites, Sentinel-2A and Sentinel-2B. An interesting infograph about the Sentinel-2 mission can be found here . The Sentinel-2 mission has the following capabilities: Multi-spectral data with 13 bands in the visible, near infrared, and short wave infrared part of the spectrum Systematic global coverage of land surfaces from 56\u00b0 S to 84\u00b0 N, coastal waters, and all of the Mediterranean Sea Revisiting every 5 days under the same viewing angles. Spatial resolution of 10 m, 20 m and 60 m 290 km field of view Free and open data policy To achieve frequent revisits and high mission availability, the two identical Sentinel-2 satellites (Sentinel-2A and Sentinel-2B) operate simultaneously. The orbit is Sun synchronous at 786 km (488 mi) altitude. Sentinel 2 data download All data captured by the ESA copernicus Sentinel program are completely freely available to the public. The most convinient way to download Sentinel data is through the Copernicus Open Access Hub, a platform dedicate to provide easy acces to the user. For this, an user account is required. To register go to registration page . To acces the data hub, go to https://scihub.copernicus.eu/ . Ex 3.1 - Downloading a Sentinel 2 Level 1C image In the first exercise, you will download an image from the Copernicus Open Access Hub. Go to https://scihub.copernicus.eu/ Klick \u2018Open hub\u2019 to access the Interactive Graphical User Interface Log in (or create an account) Zoom to Bel\u00e8m, a city in the north of Brazil, close to the gateway of the Amazon river Switch the \u2018Open street\u2019 view to \u2018sentinel-2 cloudless + Overlay\u2019 view Switch to \u2018navigation mode\u2019 Draw a rectangle around Bel\u00e8m: At the button \u2018Insert search criteria\u2019: go for \u2018advanced search\u2019 Look for a 2020 image (sensing period), Sentinel-2A, level 1C (product type) with a cloud cover of maximum 10%. Then click on the search button: Click on the search button Search for an image that contains the major part of the city (inspect the image in a quick look view ) Download this image to a folder on your computer. Sentinel file naming convention The naming of the Sentinel products follows the Compact Naming Convention: MMM_MSIXXX_YYYYMMDDHHMMSS_Nxxyy_ROOO_Txxxxx_\"Product Discriminator\".SAFE Where: MMM : is the mission ID (S2A/S2B) MSIXXX : MSIL1C denotes the Level-1C product level/ MSIL2A denotes the Level-2A product level (see \u2018radiometric correction\u2019). YYYYMMDDTHHMMSS : the datatake sensing start time Nxxyy : the Processing Baseline number (e.g. N0204) ROOO : Relative Orbit number (R001 - R143) Txxxxx : Tile Number field .SAFE : Product Format (Standard Archive Format for Europe) The products contain two dates. The first date (YYYYMMDDHHMMSS) is the datatake sensing time. The second date is the \"Product Discriminator\" field, which is 15 characters in length, and is used to distinguish between different end user products from the same datatake. Depending on the instance, the time in this field can be earlier or slightly later than the datatake sensing time. Thus, the following filename \u2018S2A_MSIL1C_20170105T013442_N0204_R031_T53NMJ_20170105T013443.SAFE\u2019 identifies a Level-1C product acquired by Sentinel-2A on the 5th of January, 2017 at 1:34:42 AM. It was acquired over Tile 53NMJ(2) during Relative Orbit 031, and processed with PDGS Processing Baseline 02.04. Ex 3.2 - naming convention Explain the different components of the name: S2A_MSIL1C_20180812T143751_N0206_R096_T19KGA_20180812T182110 (example) Other useful RS data sources Earth Explorer ESA has Sentinel-2, NASA has Landsat. However Landsat has a lower spatial resolution of 30m compared to the 10m of Sentinel-2 and Sentinel 2 has more spectral bands, Landsat imagery is probably the most used EO-data in science. This is because the Landsat program is the longest-running Earth Observation program of the entire Earth. Landsat-1 was already launched on July 23, 1972 resulting. Due to this difference, Landsat is on this moment more useful for historic land-change assessments than Sentinel-2 (launched in 2015). Landsat data is also freely avaible to the public. For this, the United States Geological Survey has created a data portal with extensive collections of EO data, with Landsat satellite imagery, Radar data, UAS data, digital line graphs, digital elevation model data, aerial photos, Sentinel satellite data, ... Link: earthexplorer.usgs.gov Other data sources Following website contains a nice overview of online free EO data sources: https://www.geoawesomeness.com/list-of-top-10-sources-of-free-remote-sensing-data/","title":"Sentinel-2 intro and download"},{"location":"P3-Sentinel2.html#the-esa-copernicus-programme","text":"Copernicus is the EU's Earth Observation Programme, looking at our planet and its environment for the ultimate benefit of all European citizens. The overall goal is achieving a global, continuous, autonomous, high quality, wide range Earth observation capacity. Under the copernicus programme, ESA is developing a series of next-generation Earth observation missions under the name of 'Sentinel' programme. This Sentinel Programme, consists of multiple satellites, each focussing on a different aspect of Earth observation: atmospheric, Oceanic and Land monitoring: Current Sentinel satellites, with their main goal. (Source: ESA) In this practical will focus on the multispectral imagery taken by Sentinel 2 satellites.","title":"The ESA Copernicus programme"},{"location":"P3-Sentinel2.html#the-sentinel-2-mission","text":"Sentinel-2 is the copernicus Earth observation mission by ESA with the goal to perform terrestrial observations in support of services such as forest monitoring, land cover changes detection, and natural disaster management. It consists of two identical satellites, Sentinel-2A and Sentinel-2B. An interesting infograph about the Sentinel-2 mission can be found here . The Sentinel-2 mission has the following capabilities: Multi-spectral data with 13 bands in the visible, near infrared, and short wave infrared part of the spectrum Systematic global coverage of land surfaces from 56\u00b0 S to 84\u00b0 N, coastal waters, and all of the Mediterranean Sea Revisiting every 5 days under the same viewing angles. Spatial resolution of 10 m, 20 m and 60 m 290 km field of view Free and open data policy To achieve frequent revisits and high mission availability, the two identical Sentinel-2 satellites (Sentinel-2A and Sentinel-2B) operate simultaneously. The orbit is Sun synchronous at 786 km (488 mi) altitude.","title":"The Sentinel-2 mission"},{"location":"P3-Sentinel2.html#sentinel-2-data-download","text":"All data captured by the ESA copernicus Sentinel program are completely freely available to the public. The most convinient way to download Sentinel data is through the Copernicus Open Access Hub, a platform dedicate to provide easy acces to the user. For this, an user account is required. To register go to registration page . To acces the data hub, go to https://scihub.copernicus.eu/ . Ex 3.1 - Downloading a Sentinel 2 Level 1C image In the first exercise, you will download an image from the Copernicus Open Access Hub. Go to https://scihub.copernicus.eu/ Klick \u2018Open hub\u2019 to access the Interactive Graphical User Interface Log in (or create an account) Zoom to Bel\u00e8m, a city in the north of Brazil, close to the gateway of the Amazon river Switch the \u2018Open street\u2019 view to \u2018sentinel-2 cloudless + Overlay\u2019 view Switch to \u2018navigation mode\u2019 Draw a rectangle around Bel\u00e8m: At the button \u2018Insert search criteria\u2019: go for \u2018advanced search\u2019 Look for a 2020 image (sensing period), Sentinel-2A, level 1C (product type) with a cloud cover of maximum 10%. Then click on the search button: Click on the search button Search for an image that contains the major part of the city (inspect the image in a quick look view ) Download this image to a folder on your computer.","title":"Sentinel 2 data download"},{"location":"P3-Sentinel2.html#sentinel-file-naming-convention","text":"The naming of the Sentinel products follows the Compact Naming Convention: MMM_MSIXXX_YYYYMMDDHHMMSS_Nxxyy_ROOO_Txxxxx_\"Product Discriminator\".SAFE Where: MMM : is the mission ID (S2A/S2B) MSIXXX : MSIL1C denotes the Level-1C product level/ MSIL2A denotes the Level-2A product level (see \u2018radiometric correction\u2019). YYYYMMDDTHHMMSS : the datatake sensing start time Nxxyy : the Processing Baseline number (e.g. N0204) ROOO : Relative Orbit number (R001 - R143) Txxxxx : Tile Number field .SAFE : Product Format (Standard Archive Format for Europe) The products contain two dates. The first date (YYYYMMDDHHMMSS) is the datatake sensing time. The second date is the \"Product Discriminator\" field, which is 15 characters in length, and is used to distinguish between different end user products from the same datatake. Depending on the instance, the time in this field can be earlier or slightly later than the datatake sensing time. Thus, the following filename \u2018S2A_MSIL1C_20170105T013442_N0204_R031_T53NMJ_20170105T013443.SAFE\u2019 identifies a Level-1C product acquired by Sentinel-2A on the 5th of January, 2017 at 1:34:42 AM. It was acquired over Tile 53NMJ(2) during Relative Orbit 031, and processed with PDGS Processing Baseline 02.04. Ex 3.2 - naming convention Explain the different components of the name: S2A_MSIL1C_20180812T143751_N0206_R096_T19KGA_20180812T182110 (example)","title":"Sentinel file naming convention"},{"location":"P3-Sentinel2.html#other-useful-rs-data-sources","text":"","title":"Other useful RS data sources"},{"location":"P3-Sentinel2.html#earth-explorer","text":"ESA has Sentinel-2, NASA has Landsat. However Landsat has a lower spatial resolution of 30m compared to the 10m of Sentinel-2 and Sentinel 2 has more spectral bands, Landsat imagery is probably the most used EO-data in science. This is because the Landsat program is the longest-running Earth Observation program of the entire Earth. Landsat-1 was already launched on July 23, 1972 resulting. Due to this difference, Landsat is on this moment more useful for historic land-change assessments than Sentinel-2 (launched in 2015). Landsat data is also freely avaible to the public. For this, the United States Geological Survey has created a data portal with extensive collections of EO data, with Landsat satellite imagery, Radar data, UAS data, digital line graphs, digital elevation model data, aerial photos, Sentinel satellite data, ... Link: earthexplorer.usgs.gov","title":"Earth Explorer"},{"location":"P3-Sentinel2.html#other-data-sources","text":"Following website contains a nice overview of online free EO data sources: https://www.geoawesomeness.com/list-of-top-10-sources-of-free-remote-sensing-data/","title":"Other data sources"},{"location":"P3-Snap-intro.html","text":"About SNAP SNAP, the SeNtinel Application Platform is developed by the ESA specifically to process Sentinel-imagery, however also other remotey sensed images can be read. The current version is 8.0.0 . SNAP is a relatively new software especially designed for the analysis of Sentinel products (Sentinel 2A was launched in 2015) and hence still contains some bugs (especially for mac-users, might try the older version 7.0.0). Not all applications are supported that you will find in classic Image Processing programs such as ENVI, but it is very user friendly and ideal to introduce you to satellite image processing. Also, it is free! Overview We will use SNAP to examine some image composites, and necessary preprocessing steps. After that, we will do most other processing with Google Earth Engine. Excercise: Opening a Sentinel-2 image in snap Open the sentinel image that you have downloaded (you do not need to unzip it). You can do this in several ways: Drag and drop the zip folder in the Products explorer Click file > Open Products and browse to your zip-folder Click and browse to your zip-folder. Unfold the image folder. Explore the files included. Open the Blue, Green, Red and NIR image. Test the tile buttons. Make sure you can see the four images simultaneously: Explore the navigation panel. Sentinel 2 Bands Let's have a quick look at the specifications of a Sentinel-2 image. There are 13 Sentinel 2 bands in total, with a resolution of 10, 20 or 60m: The navigation window The Navigation Window is used to move the viewport of an Image View, to zoom in and out of it and to rotate the image in steps of 5 degrees using the spinner control below the image preview. The current viewport is depicted by a semi-transparent rectangle, which can be dragged in order to move the viewport to another location. The navigation window In the bottom left, you will find the zoom factor: zoom is relative to the drawing extents. A scale factor of: 1 shows a part of the image 2 shows entities twice as large 0.5 shows entities half as large The text box at the left side of slider can be used to adjust the zoom factor manually. The Navigation window additionally provides the following features via its tool buttons (top right): Zoom In : Zooms in by a factor of 1.2. Zoom Out : Zooms out by a factor of 1/1.2. Zoom Actual Pixel : Sets the zoom factor to the default value so that the size of an image pixel has the same size of a display pixel. Zoom All : Adjusts the viewport to cover the entire image. Synchronise Views : Synchronises the viewports of all compatible image views. Synchronise Cursor : Displays a synchronised cursor on all opened image views. You can also zoom the images by scrolling on the image, or by clicking in the toolbar. Zoom factor vs Representative Fraction The zoom factor is not the same as a Representative Fraction (RF) , which is often used to indicate the scale of a map. The RF indicates the ratio between the number of units on the map to the number of units on the ground. The RF factor 1:100000 e.g. implies that one cm on map is equal to 1 km on land. Maps are described as either large-scale or small-scale. Large-scale maps show a smaller amount of area with a greater amount of detail. The geographic extent shown on a large-scale map is small. A large scaled map expressed as a representative scale would have a smaller number to the right of the ratio. For example, a large-scale map could have a RF scale of 1: 1,000. Large-scale maps are typically used to show neighbourhoods, a localize area, small towns, etc. Small-scale maps show a larger geographic area with few details on them. The RF scale of a small-scale map would have a much larger number to the right of the colon such as 1: 1,000,000. Small-scale maps are used to show the extent of an entire country, region, or continent. Zoom to the Airport Explore the World View panel . The red rectangle indicates the position of the image on the globe. The Colour Manipulation tool The colour manipulation tool window window is used to modify the colours used in the image. If you are opening an Image View of a data product's band, the Sentinel Toolbox either loads image settings from the product itself (BEAM-DIMAP format only) or uses default colour settings. In the Colour manipulation panel, explore the histogram. On the image, zoom to the airport and adjust the contrast. Restore the contrast afterwards. Pixel info view If you click on the tab 'Pixel View' (right to the product explorer), pixel information will be displayed while you move the mouse over the band image view.","title":"Introduction to SNAP"},{"location":"P3-Snap-intro.html#about-snap","text":"SNAP, the SeNtinel Application Platform is developed by the ESA specifically to process Sentinel-imagery, however also other remotey sensed images can be read. The current version is 8.0.0 . SNAP is a relatively new software especially designed for the analysis of Sentinel products (Sentinel 2A was launched in 2015) and hence still contains some bugs (especially for mac-users, might try the older version 7.0.0). Not all applications are supported that you will find in classic Image Processing programs such as ENVI, but it is very user friendly and ideal to introduce you to satellite image processing. Also, it is free!","title":"About SNAP"},{"location":"P3-Snap-intro.html#overview","text":"We will use SNAP to examine some image composites, and necessary preprocessing steps. After that, we will do most other processing with Google Earth Engine. Excercise: Opening a Sentinel-2 image in snap Open the sentinel image that you have downloaded (you do not need to unzip it). You can do this in several ways: Drag and drop the zip folder in the Products explorer Click file > Open Products and browse to your zip-folder Click and browse to your zip-folder. Unfold the image folder. Explore the files included. Open the Blue, Green, Red and NIR image. Test the tile buttons. Make sure you can see the four images simultaneously: Explore the navigation panel. Sentinel 2 Bands Let's have a quick look at the specifications of a Sentinel-2 image. There are 13 Sentinel 2 bands in total, with a resolution of 10, 20 or 60m:","title":"Overview"},{"location":"P3-Snap-intro.html#the-navigation-window","text":"The Navigation Window is used to move the viewport of an Image View, to zoom in and out of it and to rotate the image in steps of 5 degrees using the spinner control below the image preview. The current viewport is depicted by a semi-transparent rectangle, which can be dragged in order to move the viewport to another location. The navigation window In the bottom left, you will find the zoom factor: zoom is relative to the drawing extents. A scale factor of: 1 shows a part of the image 2 shows entities twice as large 0.5 shows entities half as large The text box at the left side of slider can be used to adjust the zoom factor manually. The Navigation window additionally provides the following features via its tool buttons (top right): Zoom In : Zooms in by a factor of 1.2. Zoom Out : Zooms out by a factor of 1/1.2. Zoom Actual Pixel : Sets the zoom factor to the default value so that the size of an image pixel has the same size of a display pixel. Zoom All : Adjusts the viewport to cover the entire image. Synchronise Views : Synchronises the viewports of all compatible image views. Synchronise Cursor : Displays a synchronised cursor on all opened image views. You can also zoom the images by scrolling on the image, or by clicking in the toolbar. Zoom factor vs Representative Fraction The zoom factor is not the same as a Representative Fraction (RF) , which is often used to indicate the scale of a map. The RF indicates the ratio between the number of units on the map to the number of units on the ground. The RF factor 1:100000 e.g. implies that one cm on map is equal to 1 km on land. Maps are described as either large-scale or small-scale. Large-scale maps show a smaller amount of area with a greater amount of detail. The geographic extent shown on a large-scale map is small. A large scaled map expressed as a representative scale would have a smaller number to the right of the ratio. For example, a large-scale map could have a RF scale of 1: 1,000. Large-scale maps are typically used to show neighbourhoods, a localize area, small towns, etc. Small-scale maps show a larger geographic area with few details on them. The RF scale of a small-scale map would have a much larger number to the right of the colon such as 1: 1,000,000. Small-scale maps are used to show the extent of an entire country, region, or continent. Zoom to the Airport Explore the World View panel . The red rectangle indicates the position of the image on the globe.","title":"The navigation window"},{"location":"P3-Snap-intro.html#the-colour-manipulation-tool","text":"The colour manipulation tool window window is used to modify the colours used in the image. If you are opening an Image View of a data product's band, the Sentinel Toolbox either loads image settings from the product itself (BEAM-DIMAP format only) or uses default colour settings. In the Colour manipulation panel, explore the histogram. On the image, zoom to the airport and adjust the contrast. Restore the contrast afterwards.","title":"The Colour Manipulation tool"},{"location":"P3-Snap-intro.html#pixel-info-view","text":"If you click on the tab 'Pixel View' (right to the product explorer), pixel information will be displayed while you move the mouse over the band image view.","title":"Pixel info view"},{"location":"P3-colour-composites-ctd.html","text":"Displaying more band combinations When you have performed an image resampling, open again the RGB image window in SNAP. You will notice that the list with possible band combinations is larger. Test some of the following band combinations and explore the colour differences. Which features are most clear on the following band combinations? Natural Colours: 4 3 2 False colour Infrared: 8 4 3 False colour Urban: 12 11 4 Agriculture: 11 8 2 Atmospheric penetration: 12 11 8a Healthy vegetation: 8 11 2 Land/Water: 8 11 4 Natural Colours with Atmospheric Removal: 12 8 3 Shortwave Infrared: 12 8 4 Vegetation Analysis: 11 8 4","title":"RGB colour composites 2"},{"location":"P3-colour-composites-ctd.html#displaying-more-band-combinations","text":"When you have performed an image resampling, open again the RGB image window in SNAP. You will notice that the list with possible band combinations is larger. Test some of the following band combinations and explore the colour differences. Which features are most clear on the following band combinations? Natural Colours: 4 3 2 False colour Infrared: 8 4 3 False colour Urban: 12 11 4 Agriculture: 11 8 2 Atmospheric penetration: 12 11 8a Healthy vegetation: 8 11 2 Land/Water: 8 11 4 Natural Colours with Atmospheric Removal: 12 8 3 Shortwave Infrared: 12 8 4 Vegetation Analysis: 11 8 4","title":"Displaying more band combinations"},{"location":"P3-colour-composites.html","text":"About colour composites Multispectral imagery, such as Sentinel-2, consists of several bands of data. As seen during in previous chapter, these bands can be displayed individually as a grey scale image (black = low reflectance, white = high reflectance), but they can also be displayed as a combination of three bands: a colour composite (NL: kleurcomposiet). When creating a colour composite: the three primary colours are used: red, green and blue. When they are combined in various proportions, different colours are produced per pixel. When 3 spectral bands (both visible as non-visible bands) are assigned to a primary colour, a colour composite is formed. By combining different proportions of the three primary colours Red, Green and Blue, various colours are created Two \"famous\" colour composites True Colour Composite The most straightforward colour composite is the true colour composite (also natural colour composite ), where the three visual primary colour bands of a multispectral image are assigned to their corresponding colour. For Sentinel 2, this composite is created as: Red: B4, Green: B3, Blue: B2. Sentinel-2 Normal Composite of Ghent. False Colour Composite Beside the 'normal' colour composites, any band of a multispectral satellite image can be assigned to the primary colour bands in a composite. In all those other cases, the colour of a target object on the image, will have a different colour compared to it's actual colour. The most famous of these is the False Colour Composite , where the NIR-band is assigned to the red colour, the red band to the green colour and the green band to the blue colour. It is very suitable to detect vegetation, since vegetation has a high reflectance in the NIR band. Clear water will appear dark-bluish, while turbid water (with a lot of sediments) will be cyan. Bare soils, roads and buildings may appear in various shades of blue, yellow or grey, depending on their composition. For Sentinel 2, this composite is created as: Red: B8, Green: B4, Blue: B3. Sentinel-2 False Colour Composite of Ghent. Opening a RGB image in SNAP Let's create our own image composites in SNAP! This is actually very easy to do. Just right-click on the image folder and click on 'Open RGB Image window': A window will appear with some possible S2 band combinations, but you can also create your own. Some typical S2 band combinations have their own name, such as (Red, Green, Blue): Natural Colour: 4 3 2 * False colour Infrared: 8 4 3 * False colour Urban: 12 11 4 Agriculture: 11 8 2 Atmospheric penetration: 12 11 8a * Healthy vegetation: 8 11 2 Land/Water: 8 11 4 Natural Colours with Atmospheric Removal: 12 8 3 Shortwave Infrared: 12 8 4 Vegetation Analysis: 11 8 4 With the current Sentinel-2 Level 1C-product open, only the band combinations with a * can now be displayed. Why is that? Excercise: open band composites Open the image as a natural colour composite Open the image as a false colour infrared composite Tile the images evenly and explore the difference in colour (for example in the areas with green vegetation).","title":"RGB colour composites"},{"location":"P3-colour-composites.html#about-colour-composites","text":"Multispectral imagery, such as Sentinel-2, consists of several bands of data. As seen during in previous chapter, these bands can be displayed individually as a grey scale image (black = low reflectance, white = high reflectance), but they can also be displayed as a combination of three bands: a colour composite (NL: kleurcomposiet). When creating a colour composite: the three primary colours are used: red, green and blue. When they are combined in various proportions, different colours are produced per pixel. When 3 spectral bands (both visible as non-visible bands) are assigned to a primary colour, a colour composite is formed. By combining different proportions of the three primary colours Red, Green and Blue, various colours are created","title":"About colour composites"},{"location":"P3-colour-composites.html#two-famous-colour-composites","text":"","title":"Two \"famous\" colour composites"},{"location":"P3-colour-composites.html#true-colour-composite","text":"The most straightforward colour composite is the true colour composite (also natural colour composite ), where the three visual primary colour bands of a multispectral image are assigned to their corresponding colour. For Sentinel 2, this composite is created as: Red: B4, Green: B3, Blue: B2. Sentinel-2 Normal Composite of Ghent.","title":"True Colour Composite"},{"location":"P3-colour-composites.html#false-colour-composite","text":"Beside the 'normal' colour composites, any band of a multispectral satellite image can be assigned to the primary colour bands in a composite. In all those other cases, the colour of a target object on the image, will have a different colour compared to it's actual colour. The most famous of these is the False Colour Composite , where the NIR-band is assigned to the red colour, the red band to the green colour and the green band to the blue colour. It is very suitable to detect vegetation, since vegetation has a high reflectance in the NIR band. Clear water will appear dark-bluish, while turbid water (with a lot of sediments) will be cyan. Bare soils, roads and buildings may appear in various shades of blue, yellow or grey, depending on their composition. For Sentinel 2, this composite is created as: Red: B8, Green: B4, Blue: B3. Sentinel-2 False Colour Composite of Ghent.","title":"False Colour Composite"},{"location":"P3-colour-composites.html#opening-a-rgb-image-in-snap","text":"Let's create our own image composites in SNAP! This is actually very easy to do. Just right-click on the image folder and click on 'Open RGB Image window': A window will appear with some possible S2 band combinations, but you can also create your own. Some typical S2 band combinations have their own name, such as (Red, Green, Blue): Natural Colour: 4 3 2 * False colour Infrared: 8 4 3 * False colour Urban: 12 11 4 Agriculture: 11 8 2 Atmospheric penetration: 12 11 8a * Healthy vegetation: 8 11 2 Land/Water: 8 11 4 Natural Colours with Atmospheric Removal: 12 8 3 Shortwave Infrared: 12 8 4 Vegetation Analysis: 11 8 4 With the current Sentinel-2 Level 1C-product open, only the band combinations with a * can now be displayed. Why is that? Excercise: open band composites Open the image as a natural colour composite Open the image as a false colour infrared composite Tile the images evenly and explore the difference in colour (for example in the areas with green vegetation).","title":"Opening a RGB image in SNAP"},{"location":"P3-image-preprocessing.html","text":"Radiometric & atmospheric correction Satellite images obtained by the sensing device are not directly usable. They need to go through a series of pre-processing before they are ready to use. The scheme below illustrates the pre-processing steps that Sentinel-images undergo before they are made available for the user. This includes geometric correction, some radiometric correction (noise reduction, defective pixels identification) the computation of cloud masks, etc. The outcome is a level 1C product, which is Top-Of-the-Atmosphere (TOA). TOA reflectances are subjected to radiometric bias caused by different lighting conditions, atmospheric interactions and viewing geometry. In order to relate reflectances to physical field properties, TOA reflectance values are conversed to BOA (Bottom Of Atmosphere) corrected reflectance values. This radiometric correction is an essential part in image processing. BOA, Sentinel processing level 2A, is available for the user (except for recent images) or can be created by the user itself, using the Sen2Cor freeware. Figure: A true color comparison of the surface reflectance product (top) and a top of atmosphere reflectance image (bottom) in adjacent scenes captured by the same satellite (Planet.com) In Snap, the conversion of level 1C TOA-reflectance to level 2A BOA-reflectance can be done through Sen2Cor (plug-in or stand-alone). Sen2Cor corrects the reflectance values based on (among others) \u2018look-up tables\u2019, these are tables that relate physical parameters to model coefficients. Parameters such as inclination and product type are sensor dependent (different for Landsat as for Sentinel or Spot). On board, optical satellites have some meteorological sensors that measure atmosphere features such as the air thickness and the amount of aerosols among others. This information is available as a \u2018header file\u2019 for each image. Since December 2018, users can download Level-2A processed products directly. In case of this exercise, we downloaded a Level 1C product. Thus, let\u2019s perform an atmospheric correction! Excercise: atmospheric correction with Sen2Cor In the folder where you have saved the image, unzip the Sentinel-image. Go to \u2018Optical\u2019 > \u2018Thematic Land Processing\u2019 > \u2018Sen2Cor processor\u2019 > \u2018Sen2Cor280\u2019 When you choose the source product, click on the \u2018\u2026\u2019, browse to the image and navigate to the \u2018MTD_MSIL1C.xml\u2019 product. In the tab \u2018processing parameters\u2019, set the resolution to \u2018ALL\u2019 The other processing parameters are by default taken from a combination of the image metadata (header file) and look-up tables. This is why you will normally use the default processing parameters. However, if you want to adjust these parameters, you can do that manually. Run Sen2Cor (!be patient, it will take a while to process the entire image.) Explore the outcome image (RGB). What differences do you see according to the original image? Installing 'Sen2Cor' plugin Possibly sen2cor isn\u2019t installed yet. To do this, go to \u2018Tools\u2019 > \u2018Plugins\u2019. During the first run, you\u2019ll get an error, after which an extra bundle will be installed. ). Intermezzo: Cloud Masks The image contain clouds. This means that there are some blind pixels, which lack information on the reflectance of the earth\u2019s surface at the sensing time. This phenomenon is very common in tropical areas with a rainy season. It is possible that over the whole period of the rainy season, you will not be able to obtain images with a cloud cover of less than 90%. In such cases, Radar imaging can be useful, but are complexer. An introduction to radar imaging will be given later in these practicals. Included in a Sentinel-2 image folder you can find some cloud masks at a resolution of 10m, 20m and 60m. These cloud masks enable the user to identify cloudy and cloud-free pixels. The masks include both dense clouds (opaque clouds) and cirrus clouds. These cloud masks are computed by a threshold algorithm. Below, the methods are described that identify the cloud pixels (for your information). Identification of dense clouds Dense clouds, also called opaque clouds, are characterised by a high reflectance in the blue spectral region (B2). The method used to identify dense cloud pixels is based on B2 reflectance threshold. To avoid false detection, mainly due to snow/cloud confusion, SWIR reflectance in B11 and B12 are also used. Snow and clouds both have a high reflectance in the blue. Cloud reflectance is high in the SWIR, whereas snow presents a low reflectance. Additional criteria based on B10 reflectance are added to avoid high altitude ice cloud and snow confusion (both having a low reflectance in the SWIR bands B11 and B12). At B10, there is a high atmospheric absorption band and only high altitude clouds are detected. However, this last criterion is only applied after a first detection of cloud pixel in the blue band where cirrus is transparent. Identification of cirrus clouds Cirrus clouds are thin, transparent or semi-transparent clouds, forming at high altitudes, approximately 6-7 km above the Earth's surface. The method of identifying cirrus cloud pixels from dense cloud pixel is based on two spectral criteria: (1) B10 corresponds to a high atmospheric absorption band: only high altitude clouds can be detected, (2) cirrus clouds, being semi-transparent, cannot be detected in the B2 blue band. A pixel with low reflectance in the B2 band and high reflectance in the B10 band has a good probability of being cirrus cloud but this is not a certainty. Some opaque clouds have a low reflectance in the blue and can be identified as cirrus cloud. To limit false detections (due to high reflectance in the blue or due to the fact that clouds are not spectrally registered), a filter using morphology-based operations is applied on both dense and cirrus cloud masks: (1) erosion, to remove isolated pixels, (2) dilatation, to fill the gap and extend clouds. If after morphology operations, a pixel is both dense and cirrus, the dense cloud mask prevails. Sen2Cor scene classification The Sen2Cor-processor you've runned for the atmospheric correction from the level 1C to the level 2A product also contains a scene classification algorithm. This algorithm creates a scene classification, where pixels als classified in some broad classes: Here, clouds are classified into 'cloud probability masks', which are in general more precise than the level 1C cloud masks. Excercise: Visualize cloud masks Visualize the cloud masks. If you look at the cloud masks, you will see that these are not very precise. These cloud masks are useful for rough estimations. Later we will see alternative ways to identify cloud pixels more precise. Resampling In order to display the other band combinations, some geometrical pre-processing is necessary. The bands have to be resampled to an equal resolution. The goal is to resample the image bands to 10m (you can take B2, B3, B4 or B8 as a reference band). This means that all other bands will be upsampled. Image resampling scheme. Top: upsampling (nearest neighbor). Bottom: Downsampling (minimum). Exercise: resampling In the product explorer, select the outcome image of Sen2Cor. Go to Raster > Geometric operations > Resampling . Select the \u2018Save as\u2026 BEAM-DIMAP\u2019 box. Browse to your directory. Choose a logical name for the target product. Resampling Parameters: Choose a reference band that has a resolution of 10m, or choose for a pixel resolution of 10m. Use an upsampling method of your choice (Read the help for more details on the different algorithms). Run resampling . Saving the images takes a lot of time. Again, be patient! Image Subsetting Processing an entire Sentinel image takes a lot of processing capacity and time (as you probably have noted already). Therefore, you will now learn how to only process a small part of the image. You can choose to reduce the spatial extent of the image, or you can choose to reduce the amount of bands in the image, or a combination of both. An important aspect is that creating a subset is only possible for bands that have the same size. Thus, this will only be possible after resampling . Excercise: subsetting an image Select the resampled image in the product explorer. Go to Raster > Subset. Select a spatial subset by choice (by adjusting the scene start and end). Make sure your spatial extent is substantially smaller than the original image. Snap Subsetting screen. Select only following bands: [B2, B3, B4, B5, B6, B7, B8, B8A, B11, B12] You can see an estimation of the new required storage space. Snap Subsetting screen. Click OK Another option to make a subset is \u2018Spatial subset from view\u2019. Zoom in on your image. Rightclick and select \u2018Spatial subset from view\u2019. FYI: it is also possible to take a subset of an image, based on a vector layer. Mosaicing Mosaicing is the merging of several arbitrarily shaped images and often used to merge two neighbouring satellite images. Excercise: mosaicing Download an image that is located next to the image you are already working with, dating from the same time as the original image was taken. You can download it directly in Level 2A, thus skipping the sen2cor atmospheric correction. Resample the image. Go to raster > Geometric operations > Mosaicing Snap mosaicing screen. Add the two source products. Choose the directory in which you want to save the mosaic image. In the Map Projection Definition you can choose the Coordinate Reference System (CRS). Choose for UTM/WGS84 (automatic) Choose for a resolution of 10m. The input products don\u2019t need to be orthorectified (because they already are). In the tab \u2018Variables and Conditions\u2019, click the - symbol. Select Band 2,3,4 and 8 Run Mosaicing. Open the RGB-image of the product. Compare it to the two original images. Extra: Examine the example of Landsat satellite image after merging below. What went wrong when mosaicing images 1 and 2? Why is there a colour difference in 2 and 3? Why is there no observable colour difference in 2 and 4? Have you any idea how to eliminate the colour difference between 2 and 3, given that neighbouring satellite images always partly overlap? Landsat images mosaic","title":"Image preprocessing in SNAP"},{"location":"P3-image-preprocessing.html#radiometric-atmospheric-correction","text":"Satellite images obtained by the sensing device are not directly usable. They need to go through a series of pre-processing before they are ready to use. The scheme below illustrates the pre-processing steps that Sentinel-images undergo before they are made available for the user. This includes geometric correction, some radiometric correction (noise reduction, defective pixels identification) the computation of cloud masks, etc. The outcome is a level 1C product, which is Top-Of-the-Atmosphere (TOA). TOA reflectances are subjected to radiometric bias caused by different lighting conditions, atmospheric interactions and viewing geometry. In order to relate reflectances to physical field properties, TOA reflectance values are conversed to BOA (Bottom Of Atmosphere) corrected reflectance values. This radiometric correction is an essential part in image processing. BOA, Sentinel processing level 2A, is available for the user (except for recent images) or can be created by the user itself, using the Sen2Cor freeware. Figure: A true color comparison of the surface reflectance product (top) and a top of atmosphere reflectance image (bottom) in adjacent scenes captured by the same satellite (Planet.com) In Snap, the conversion of level 1C TOA-reflectance to level 2A BOA-reflectance can be done through Sen2Cor (plug-in or stand-alone). Sen2Cor corrects the reflectance values based on (among others) \u2018look-up tables\u2019, these are tables that relate physical parameters to model coefficients. Parameters such as inclination and product type are sensor dependent (different for Landsat as for Sentinel or Spot). On board, optical satellites have some meteorological sensors that measure atmosphere features such as the air thickness and the amount of aerosols among others. This information is available as a \u2018header file\u2019 for each image. Since December 2018, users can download Level-2A processed products directly. In case of this exercise, we downloaded a Level 1C product. Thus, let\u2019s perform an atmospheric correction! Excercise: atmospheric correction with Sen2Cor In the folder where you have saved the image, unzip the Sentinel-image. Go to \u2018Optical\u2019 > \u2018Thematic Land Processing\u2019 > \u2018Sen2Cor processor\u2019 > \u2018Sen2Cor280\u2019 When you choose the source product, click on the \u2018\u2026\u2019, browse to the image and navigate to the \u2018MTD_MSIL1C.xml\u2019 product. In the tab \u2018processing parameters\u2019, set the resolution to \u2018ALL\u2019 The other processing parameters are by default taken from a combination of the image metadata (header file) and look-up tables. This is why you will normally use the default processing parameters. However, if you want to adjust these parameters, you can do that manually. Run Sen2Cor (!be patient, it will take a while to process the entire image.) Explore the outcome image (RGB). What differences do you see according to the original image? Installing 'Sen2Cor' plugin Possibly sen2cor isn\u2019t installed yet. To do this, go to \u2018Tools\u2019 > \u2018Plugins\u2019. During the first run, you\u2019ll get an error, after which an extra bundle will be installed. ).","title":"Radiometric &amp; atmospheric correction"},{"location":"P3-image-preprocessing.html#intermezzo-cloud-masks","text":"The image contain clouds. This means that there are some blind pixels, which lack information on the reflectance of the earth\u2019s surface at the sensing time. This phenomenon is very common in tropical areas with a rainy season. It is possible that over the whole period of the rainy season, you will not be able to obtain images with a cloud cover of less than 90%. In such cases, Radar imaging can be useful, but are complexer. An introduction to radar imaging will be given later in these practicals. Included in a Sentinel-2 image folder you can find some cloud masks at a resolution of 10m, 20m and 60m. These cloud masks enable the user to identify cloudy and cloud-free pixels. The masks include both dense clouds (opaque clouds) and cirrus clouds. These cloud masks are computed by a threshold algorithm. Below, the methods are described that identify the cloud pixels (for your information). Identification of dense clouds Dense clouds, also called opaque clouds, are characterised by a high reflectance in the blue spectral region (B2). The method used to identify dense cloud pixels is based on B2 reflectance threshold. To avoid false detection, mainly due to snow/cloud confusion, SWIR reflectance in B11 and B12 are also used. Snow and clouds both have a high reflectance in the blue. Cloud reflectance is high in the SWIR, whereas snow presents a low reflectance. Additional criteria based on B10 reflectance are added to avoid high altitude ice cloud and snow confusion (both having a low reflectance in the SWIR bands B11 and B12). At B10, there is a high atmospheric absorption band and only high altitude clouds are detected. However, this last criterion is only applied after a first detection of cloud pixel in the blue band where cirrus is transparent. Identification of cirrus clouds Cirrus clouds are thin, transparent or semi-transparent clouds, forming at high altitudes, approximately 6-7 km above the Earth's surface. The method of identifying cirrus cloud pixels from dense cloud pixel is based on two spectral criteria: (1) B10 corresponds to a high atmospheric absorption band: only high altitude clouds can be detected, (2) cirrus clouds, being semi-transparent, cannot be detected in the B2 blue band. A pixel with low reflectance in the B2 band and high reflectance in the B10 band has a good probability of being cirrus cloud but this is not a certainty. Some opaque clouds have a low reflectance in the blue and can be identified as cirrus cloud. To limit false detections (due to high reflectance in the blue or due to the fact that clouds are not spectrally registered), a filter using morphology-based operations is applied on both dense and cirrus cloud masks: (1) erosion, to remove isolated pixels, (2) dilatation, to fill the gap and extend clouds. If after morphology operations, a pixel is both dense and cirrus, the dense cloud mask prevails. Sen2Cor scene classification The Sen2Cor-processor you've runned for the atmospheric correction from the level 1C to the level 2A product also contains a scene classification algorithm. This algorithm creates a scene classification, where pixels als classified in some broad classes: Here, clouds are classified into 'cloud probability masks', which are in general more precise than the level 1C cloud masks. Excercise: Visualize cloud masks Visualize the cloud masks. If you look at the cloud masks, you will see that these are not very precise. These cloud masks are useful for rough estimations. Later we will see alternative ways to identify cloud pixels more precise.","title":"Intermezzo: Cloud Masks"},{"location":"P3-image-preprocessing.html#resampling","text":"In order to display the other band combinations, some geometrical pre-processing is necessary. The bands have to be resampled to an equal resolution. The goal is to resample the image bands to 10m (you can take B2, B3, B4 or B8 as a reference band). This means that all other bands will be upsampled. Image resampling scheme. Top: upsampling (nearest neighbor). Bottom: Downsampling (minimum). Exercise: resampling In the product explorer, select the outcome image of Sen2Cor. Go to Raster > Geometric operations > Resampling . Select the \u2018Save as\u2026 BEAM-DIMAP\u2019 box. Browse to your directory. Choose a logical name for the target product. Resampling Parameters: Choose a reference band that has a resolution of 10m, or choose for a pixel resolution of 10m. Use an upsampling method of your choice (Read the help for more details on the different algorithms). Run resampling . Saving the images takes a lot of time. Again, be patient!","title":"Resampling"},{"location":"P3-image-preprocessing.html#image-subsetting","text":"Processing an entire Sentinel image takes a lot of processing capacity and time (as you probably have noted already). Therefore, you will now learn how to only process a small part of the image. You can choose to reduce the spatial extent of the image, or you can choose to reduce the amount of bands in the image, or a combination of both. An important aspect is that creating a subset is only possible for bands that have the same size. Thus, this will only be possible after resampling . Excercise: subsetting an image Select the resampled image in the product explorer. Go to Raster > Subset. Select a spatial subset by choice (by adjusting the scene start and end). Make sure your spatial extent is substantially smaller than the original image. Snap Subsetting screen. Select only following bands: [B2, B3, B4, B5, B6, B7, B8, B8A, B11, B12] You can see an estimation of the new required storage space. Snap Subsetting screen. Click OK Another option to make a subset is \u2018Spatial subset from view\u2019. Zoom in on your image. Rightclick and select \u2018Spatial subset from view\u2019. FYI: it is also possible to take a subset of an image, based on a vector layer.","title":"Image Subsetting"},{"location":"P3-image-preprocessing.html#mosaicing","text":"Mosaicing is the merging of several arbitrarily shaped images and often used to merge two neighbouring satellite images. Excercise: mosaicing Download an image that is located next to the image you are already working with, dating from the same time as the original image was taken. You can download it directly in Level 2A, thus skipping the sen2cor atmospheric correction. Resample the image. Go to raster > Geometric operations > Mosaicing Snap mosaicing screen. Add the two source products. Choose the directory in which you want to save the mosaic image. In the Map Projection Definition you can choose the Coordinate Reference System (CRS). Choose for UTM/WGS84 (automatic) Choose for a resolution of 10m. The input products don\u2019t need to be orthorectified (because they already are). In the tab \u2018Variables and Conditions\u2019, click the - symbol. Select Band 2,3,4 and 8 Run Mosaicing. Open the RGB-image of the product. Compare it to the two original images. Extra: Examine the example of Landsat satellite image after merging below. What went wrong when mosaicing images 1 and 2? Why is there a colour difference in 2 and 3? Why is there no observable colour difference in 2 and 4? Have you any idea how to eliminate the colour difference between 2 and 3, given that neighbouring satellite images always partly overlap? Landsat images mosaic","title":"Mosaicing"},{"location":"P3-intro.html","text":"Practicum 3: Image download & preprocessing Doel van het practicum Downloaden van remote sensing data: via ESA sentinel hub via andere bronnen Introductie tot ESA SNAP: Inlezen van RS beelden Basisfunctionaliteiten Aanmaken van beeldcomposieten SNAP vs andere software Beeldvoorbewerking in SNAP (Sentinel 2): Radiometrische/atmospherische correctie Resampling Subsetting Mosaicing","title":"Introduction"},{"location":"P3-intro.html#practicum-3-image-download-preprocessing","text":"","title":"Practicum 3: Image download &amp; preprocessing"},{"location":"P3-intro.html#doel-van-het-practicum","text":"Downloaden van remote sensing data: via ESA sentinel hub via andere bronnen Introductie tot ESA SNAP: Inlezen van RS beelden Basisfunctionaliteiten Aanmaken van beeldcomposieten SNAP vs andere software Beeldvoorbewerking in SNAP (Sentinel 2): Radiometrische/atmospherische correctie Resampling Subsetting Mosaicing","title":"Doel van het practicum"},{"location":"P4/P4-Cloud_masking.html","text":"Cloud Masking Wolkbedekking is een grote barri\u00e8re tijdens het analyseren en processen van (spectrale) satellietbeelden. Recente satellietdata komen veelal ook met automatische classificaties van de wolkbedekking, waardoor deze relatief eenvoudig uit het beeld verwijderd kunnen worden (zie ook P3: cloud masking ). Earth engine bevat naast deze standaard \u2018cloud masks\u2019 ook eigen algoritmes om de wolken en wolkschaduw te verwijderen uit het beeld, maar bevat ook enkele andere mogelijkheden om de aanwezigheid ervan veel mogelijk te minimaliseren zoals het toepassen van reducties op beeldcollecties. 1) Filteren van de ImageCollection op wolkbedekking Een eerste optie is om een beeldcollectie te filteren (zie voorgaand ) op wolkbedekking, waardoor enkel de beelden binnen een paalde range van wolkenpercentages worden weerhouden: FilterMetaData Bij de voorgande filters gebruikten we de redelijk eenvoudige functies .filterBounds() en .filterDate() , twee standaardfilters om op respectievelijk locatie (van een geometrie) en datum te filter. De functie .filterMetadata() wordt gebruikt om te filteren op eender welke Metadata-eigenschap dat een beeld bevat. Gebruik de Docs om het gebruik van deze functie verder te bekijken. 2) Cloud Masking optie 1 Als 2e stap kunnen de overgebleven wolken/wolkschaduwen per beeld worden \u2018geknipt\u2019 (cloudmask) door deze pixels naar een waarde 0 om te zetten. Een standaard algoritme is bij de meeste beelden reeds gegeven als voorbeeld onderaan in de catalogus: Voor Landsat-8 : https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR Voor Sentinel 2 : https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR ). Voor Landsat 8 wordt dit bijgevolg: L8 = L8 . filterMetadata ( 'CLOUD_COVER' , 'less_than' , 30 ) function maskL8sr ( image ) { // Bits 3 and 5 are cloud shadow and cloud, respectively. var cloudShadowBitMask = ( 1 << 3 ); var cloudsBitMask = ( 1 << 5 ); // Get the pixel QA band. var qa = image . select ( 'pixel_qa' ); // Both flags should be set to zero, indicating clear conditions. var mask = qa . bitwiseAnd ( cloudShadowBitMask ). eq ( 0 ) . and ( qa . bitwiseAnd ( cloudsBitMask ). eq ( 0 )); return image . updateMask ( mask ); } // Pas de functie over elk beeld binnen de collectie toe: var L8_masked = L8 . map ( maskL8sr ); Resulterend is een ImageCollectie met dezelfde beelden, maar waaruit de wolken gemaskeerd zijn (mask toegepast). Echter kunnen wel sommige wolkenranden nog zichtbaar zijn, die de mask-functies hebben gemist. OPDRACHT Maak de L8_masked collectie aan, en neem hiervan een .median() reducer. Visualiseer dit beeld. Merk je een verbetering in vergelijking met de voorgande .median()-gereduceerde beelden, zonder de cloudmask ? De .map()-functie In bovenstaand voorbeeld werd de cloudmask-functie toegepast door gebruik te maken van .map() . D .map() wordt steeds gebruikt om een functie (die op afzonderlijke beelden dient toegepast te worden, zoals maskL8sr ) toe te passen over elk beeld binnen een ImageCollection afzonderlijk. Het is als het ware een veel effici\u00ebnte manier dan de aangemaakte functie te itereren via een for-loop.","title":"Cloud masking"},{"location":"P4/P4-Cloud_masking.html#cloud-masking","text":"Wolkbedekking is een grote barri\u00e8re tijdens het analyseren en processen van (spectrale) satellietbeelden. Recente satellietdata komen veelal ook met automatische classificaties van de wolkbedekking, waardoor deze relatief eenvoudig uit het beeld verwijderd kunnen worden (zie ook P3: cloud masking ). Earth engine bevat naast deze standaard \u2018cloud masks\u2019 ook eigen algoritmes om de wolken en wolkschaduw te verwijderen uit het beeld, maar bevat ook enkele andere mogelijkheden om de aanwezigheid ervan veel mogelijk te minimaliseren zoals het toepassen van reducties op beeldcollecties.","title":"Cloud Masking"},{"location":"P4/P4-Cloud_masking.html#1-filteren-van-de-imagecollection-op-wolkbedekking","text":"Een eerste optie is om een beeldcollectie te filteren (zie voorgaand ) op wolkbedekking, waardoor enkel de beelden binnen een paalde range van wolkenpercentages worden weerhouden: FilterMetaData Bij de voorgande filters gebruikten we de redelijk eenvoudige functies .filterBounds() en .filterDate() , twee standaardfilters om op respectievelijk locatie (van een geometrie) en datum te filter. De functie .filterMetadata() wordt gebruikt om te filteren op eender welke Metadata-eigenschap dat een beeld bevat. Gebruik de Docs om het gebruik van deze functie verder te bekijken.","title":"1) Filteren van de ImageCollection op wolkbedekking"},{"location":"P4/P4-Cloud_masking.html#2-cloud-masking-optie-1","text":"Als 2e stap kunnen de overgebleven wolken/wolkschaduwen per beeld worden \u2018geknipt\u2019 (cloudmask) door deze pixels naar een waarde 0 om te zetten. Een standaard algoritme is bij de meeste beelden reeds gegeven als voorbeeld onderaan in de catalogus: Voor Landsat-8 : https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR Voor Sentinel 2 : https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR ). Voor Landsat 8 wordt dit bijgevolg: L8 = L8 . filterMetadata ( 'CLOUD_COVER' , 'less_than' , 30 ) function maskL8sr ( image ) { // Bits 3 and 5 are cloud shadow and cloud, respectively. var cloudShadowBitMask = ( 1 << 3 ); var cloudsBitMask = ( 1 << 5 ); // Get the pixel QA band. var qa = image . select ( 'pixel_qa' ); // Both flags should be set to zero, indicating clear conditions. var mask = qa . bitwiseAnd ( cloudShadowBitMask ). eq ( 0 ) . and ( qa . bitwiseAnd ( cloudsBitMask ). eq ( 0 )); return image . updateMask ( mask ); } // Pas de functie over elk beeld binnen de collectie toe: var L8_masked = L8 . map ( maskL8sr ); Resulterend is een ImageCollectie met dezelfde beelden, maar waaruit de wolken gemaskeerd zijn (mask toegepast). Echter kunnen wel sommige wolkenranden nog zichtbaar zijn, die de mask-functies hebben gemist.","title":"2) Cloud Masking optie 1"},{"location":"P4/P4-Cloud_masking.html#opdracht","text":"Maak de L8_masked collectie aan, en neem hiervan een .median() reducer. Visualiseer dit beeld. Merk je een verbetering in vergelijking met de voorgande .median()-gereduceerde beelden, zonder de cloudmask ? De .map()-functie In bovenstaand voorbeeld werd de cloudmask-functie toegepast door gebruik te maken van .map() . D .map() wordt steeds gebruikt om een functie (die op afzonderlijke beelden dient toegepast te worden, zoals maskL8sr ) toe te passen over elk beeld binnen een ImageCollection afzonderlijk. Het is als het ware een veel effici\u00ebnte manier dan de aangemaakte functie te itereren via een for-loop.","title":"OPDRACHT"},{"location":"P4/P4-DataCatalog.html","text":"De Earth Engine Data Catalog Om het aanbod aan Aardobservatie-data in GEE te bekijken en te doorzoeken, kan gebruik gemaakt worden van de Data Catalog: https://developers.google.com/earth-engine/datasets . Via deze catalogus kun je eenvoudig rasterdata allerhande opzoeken en de noodzakelijke code om de beelden in je script te importeren vinden. In de komende voorbeeldoefening maken we gebruik van Landsat-data. Zoek in de Earth Engine Data Catalog naar een geschikte Landsat datacollectie, dat het jaar 2020 omvat. In Earth Engine zijn Landsatbeelden eerste instantie opgedeeld op basis van de uitgevoerde correcties ( 'Surface reflectance' , 'Top-Of-Atmosphere' , 'Raw Images' ), anderzijds op basis van de kwaliteit: Tier 1 : De meest kwalitatieve beelden, geschikt voor tijdserie-analyse. De beelden zijn zowel geometrisch als radiometrisch kwalitatief goed bevonden. Tier 2 : De beelden zijn geometrisch en/of radiometrisch minder kwalitatief bevonden, maar kunnen voor bepaalde doeleinden wel nog inzetbaar zijn. Tier 1 + Real-Time : De Tier-1 database uitgebreid met de meest recente data die nog niet kwalitatief zijn gekeurd en bijgevolg dus nog fouten kunnen bevatten. Het Landsat programma Landsat is het langst lopende aardobservatie satellietprogramma en is sinds 1972 continue operationeel. Het is een samenwerking tussen de United States Geological Survey (USGS) en de NASA. De meest recente lancering was deze van Landsat 8 in 2013, de lancering van Landsat 9 gepland staat voor 2022. Onderstaande grafiek geeft een vergelijking tussen de bandverdeling van de huidige operationele Landsatsatellieten: Landsat 8 (OLI/TIRS) en Landsat 7 (Bron: NASA )","title":"EarthEngine data catalog"},{"location":"P4/P4-DataCatalog.html#de-earth-engine-data-catalog","text":"Om het aanbod aan Aardobservatie-data in GEE te bekijken en te doorzoeken, kan gebruik gemaakt worden van de Data Catalog: https://developers.google.com/earth-engine/datasets . Via deze catalogus kun je eenvoudig rasterdata allerhande opzoeken en de noodzakelijke code om de beelden in je script te importeren vinden. In de komende voorbeeldoefening maken we gebruik van Landsat-data. Zoek in de Earth Engine Data Catalog naar een geschikte Landsat datacollectie, dat het jaar 2020 omvat. In Earth Engine zijn Landsatbeelden eerste instantie opgedeeld op basis van de uitgevoerde correcties ( 'Surface reflectance' , 'Top-Of-Atmosphere' , 'Raw Images' ), anderzijds op basis van de kwaliteit: Tier 1 : De meest kwalitatieve beelden, geschikt voor tijdserie-analyse. De beelden zijn zowel geometrisch als radiometrisch kwalitatief goed bevonden. Tier 2 : De beelden zijn geometrisch en/of radiometrisch minder kwalitatief bevonden, maar kunnen voor bepaalde doeleinden wel nog inzetbaar zijn. Tier 1 + Real-Time : De Tier-1 database uitgebreid met de meest recente data die nog niet kwalitatief zijn gekeurd en bijgevolg dus nog fouten kunnen bevatten. Het Landsat programma Landsat is het langst lopende aardobservatie satellietprogramma en is sinds 1972 continue operationeel. Het is een samenwerking tussen de United States Geological Survey (USGS) en de NASA. De meest recente lancering was deze van Landsat 8 in 2013, de lancering van Landsat 9 gepland staat voor 2022. Onderstaande grafiek geeft een vergelijking tussen de bandverdeling van de huidige operationele Landsatsatellieten: Landsat 8 (OLI/TIRS) en Landsat 7 (Bron: NASA )","title":"De Earth Engine Data Catalog"},{"location":"P4/P4-Goals.html","text":"Doel van dit practicum In dit practicum maken we kennis met het Google Earth Engine. We behandelen hoe data kan opgezocht en gevisualiseerd worden en hoe data over een bepaalde tijdsperiode te aggregeren. We maken hierbij gebruik van zowel Landsat-8 beelden als Sentinel-2. Voorbereiding Voor dit practicum heb je enkel een laptop nodig waarop - bij voorkeur - Google Chrome op is ge\u00efnstalleerd. Verder heb je ook een Google Earth Engine account nodig. Deze kun je gratis aanmaken via https://earthengine.google.com/new_signup/ . Indien je dit nog niet hebt gedaan, gelieve dit dan te doen.","title":"Doel van het practicum"},{"location":"P4/P4-Goals.html#doel-van-dit-practicum","text":"In dit practicum maken we kennis met het Google Earth Engine. We behandelen hoe data kan opgezocht en gevisualiseerd worden en hoe data over een bepaalde tijdsperiode te aggregeren. We maken hierbij gebruik van zowel Landsat-8 beelden als Sentinel-2.","title":"Doel van dit practicum"},{"location":"P4/P4-Goals.html#voorbereiding","text":"Voor dit practicum heb je enkel een laptop nodig waarop - bij voorkeur - Google Chrome op is ge\u00efnstalleerd. Verder heb je ook een Google Earth Engine account nodig. Deze kun je gratis aanmaken via https://earthengine.google.com/new_signup/ . Indien je dit nog niet hebt gedaan, gelieve dit dan te doen.","title":"Voorbereiding"},{"location":"P4/P4-ImageVisualization.html","text":"Visualisatie van een enkelvoudig satellietbeeld Laten we simpel starten met het afbeelden van een enkel rasterbeeld. In Practicum 3 gingen we te werk met een Sentinel-2 beeld van de Braziliaanse stad B\u00e9lem uit 2020. Aangezien de volledige Sentinel-bibliotheek beschikbaar is binnen Earth Engine, kan dit beeld eenvoudig worden ingeladen. Bekijk hiervoor eerst de naam nog eens van je gedownload S2-bestand, bijvoorbeeld: S2B_MSIL1C_ 20200808T134219_N0209_R124_T22MGD _20200808T153444.SAFE In Earth Engine is het vette gedeelte van de filenaam belangrijk. Dit wordt als volgt in earth-engine ingeladen, via 'ee.Image' : //Voorbeeld: Sentinel-2 beeld van vorig practicum var S2_Belem = ee . Image ( 'COPERNICUS/S2_SR/20200808T134219_20200808T134214_T22MGD' ) print ( S2_Belem ) // Zoom in de Map-view in naar het beeld, met Zoom-factor 9 Map . centerObject ( S2_Belem , 9 ); Hiermee werd slechts een variabele aangemaakt die het beeld omvat. Om het beeld te visualiseren wordt gebruik gemaakt van de functie Map.addLayer() : //Visualiseren van het satellietbeeld Map . addLayer ( S2_Belem ); Bij het uitvoeren van bovenstaande code bekomen we een zwart vlak, niet bepaald de visualisatie die we wensen. Bij het uitvoeren van bovenstaande code bekomen we een zwart vlak, niet bepaald de visualisatie die we wensen. Dit komt omdat we nog geen visualisatieparameters hebben aangegeven, waardoor de eerste 3 banden naar de rode, groene en blauwe band respectievelijk worden toegekend en de pixelrange zo groot is dat alle pixels een zwarte kleur krijgen. Om dit manueel aan te passen, zoek je je toegevoegde laag in 'Layers' in de Map-view. Klik op het tandwieltje. Een visualisatie-scherm springt open. Pas de parameters aan, zodat je een normale kleurencomposiet verkrijgt, met een stretch van 3 gamma en druk op 'Apply'. Een visueel beter resultaat wordt verkregen. Handmatig instellen van de visualisatieparameters kan via 'Layers' in de Map view Het is echter niet handig om steeds opnieuw de visualisatie handmatig in te stellen. Gelukkig kan deze ook als code ge\u00efmporteerd worden in GEE (klik op 'Import'). De visualisatieparameters worden toegevoegd in de Imports. Deze kunnen dan in de Map.addLayer() -functie worden meegeven tijdens het visualiseren. In de code-editor zelf kunnen de visualisatieparameters eveneens gedefinieerd worden. // Aanmaken van visualizatieparameters var visualization = { min : 0 , max : 3000 , bands : [ 'B4' , 'B3' , 'B2' ], }; Map . centerObject ( S2_Belem , 9 ); Map . addLayer ( S2_Belem , visualization , 'B\u00e8lem_met_Vis' ); Beeldcollecties zoeken en filteren In voorgaande paragraaf visualiseerden we een Sentinel-2 beeld die we reeds hadden opgezocht waarvan wisten dat de kwaliteit goed zat \u00e9n waarvan we de bestandsnaam reeds kenden. Het is natuurlijk niet handig om steeds een filenaam te moeten kennen om verder te kunnen werken in Earth Engine. Daarmee zouden we ook de geweldige kracht van het programma om doorheen vele petabytes aan Aardobservatiedata te zoeken onbenut laten. In wat volgt gaan we op basis van een locatie op zoek gaan naar geschikte satellietbeelden, door het filteren van gehele beeldcollecties. Area of Interest (AOI) Starten doen we met het intekenen van een gewenste Area Of Interest (AOI) in de Map View. Een AOI is niets anders dan de afbakening van het studiegebied, waarbinnen we onze data wensen te verkrijgen. Er kan rechtstreeks gezoomd worden naar een locatie via de zoekbalk bovenaan of door het scrollen met de muis. Teken vervolgs een gewenste gebied in door gebruik te maken van de toolknoppen in de \"Map View\": . In dit voorbeeld kiezen we voor de Konigin der badsteden, Oostende, als studiegebied: Automatisch wordt een nieuwe variabele aangemaakt onder de naam 'geometry', welke eenvoudig hernoemd kan worden naar een eenvoudig te gebruiken variabelenaam: Bekijk de eigenschappen van de polygoon door het naar de console te printen: //Polygoon-informatie naar de console schrijven: print ( Oostende ) Datacollecties Filteren en Visualiseren Voor deze oefening maken we als afwisseling gebruik van Landsat-8 beelden (zie ook het stukje omtrent de Earth Engine data catalog ). De importeer-code kan gekopieerd worden uit de data catalog en ziet er als volgt uit: var L8 = ee . ImageCollection ( 'LANDSAT/LC08/C01/T1_SR' ) print ( 'Grootte van de L8-collectie :' , L8 . size ()) Hiermee verwijst de variabele 'L8' naar de volledige Landsat-8 collectie (surface reflectance). De '.size()'-functie geeft het aantal beelden dat in deze collectie zijn begrepen. Een hele hoop, sinds ze collectie veel beelden van de volledige aarde omvat. Deze verzameling dient bijgevolg gefilterd te worden. Filteren kan op basis van de metadata: //Filteren o.b.v. datum, locatie: var L8 = L8 . filterDate ( '2020-01-01' , '2020-10-30' ) //Op basis van datum . filterBounds ( Oostende ) //op basis van locatie (de AOI); //Printen van de nieuwe grootte print ( 'L8 size na filtering' , L8 . size ()) // Printen van de collectie voor inspectie print ( 'Filtered collection: ' , L8 ) De beelden in de collectie zijn standaard gesorteerd op datum, indien we dus het bovenste beeld eruit halen, zal dit het eerste Landsat-8 beeld zijn gemaakt in 2020. Met de functie .first() , halen we deze eruit. Print deze naar de console en bekijk het verschil met de de Imagecollectie. // Krijg het eerste (standaard oudste) beeld uit de collectie: var L8_first = L8 . first () print ( 'Eerste Beeld:' , L8_first ) In een volgende stap kunnen we dit beeld ook gaan visualiseren, met javascript Map.addLayer() . 6) Ook nu kunnen we dit als een echte kleurencomposiet visualiseren (voor Landsat 8 betekent dit dus B2 (blauw), B3 (groen) en B4 (rood)). // Landsat-8 visualisatie instellen. var trueColor = { bands : [ 'B4' , 'B3' , 'B2' ], min : 0 , max : 3000 , gamma : 1.4 , }; Map . addLayer ( L8_first , trueColor , 'L8_TrueColorComposite' ) Eerste Landsat 8 beeld binnen de gefilterede collectie Mogelijk is dit eerste beeld niet het meest ideale wat betreft de wolkbedekking, waardoor er weinig te zien valt. Laten we nu op zoek gaan naar het beeld met de laagste wolkenbedekking binnen de collectie. Dit doen we in eerste instantie door de collectie te sorteren volgens het percentage cloudcover, wat standaard tot de metadata van een Landsatbeeld behoort. Bekijk het beeld. Wat valt je op? Wordt het volledige gebied bedekt? //Sorteren van de collectie obv cloud cover var L8_sortedCC = L8 . sort ( 'CLOUD_COVER' , true ); Map . addLayer ( L8_sortedCC . first (), trueColor , 'Least Cloud cover 2020' ) Landsat 8-beeld met laagste wolkbedekking binnen de gefilterede collectie Bekijk op welke dag de sensor dit beeld heeft genomen. Gebruik hiervoor de \u2018inspector\u2019 om de beeldeigenschappen verder te bekijken. De inspector Opdracht Visualiseer in een nieuw script een valse kleurencomposiet van een Sentinel-2 beeld (Tier 1, Surface Reflectance). Neem hierbij Gent als AOI, met een beeld uit de zomer van 2019 met een zo laag mogelijke wolkenbedekking. Voor het sorteren van de wolkenbedekking, zoek je de gepaste eigenschap om op te sorteren. Deze kun je hier vinden. Bewaar je script.","title":"Satellietdata oproepen, filteren en visualiseren"},{"location":"P4/P4-ImageVisualization.html#visualisatie-van-een-enkelvoudig-satellietbeeld","text":"Laten we simpel starten met het afbeelden van een enkel rasterbeeld. In Practicum 3 gingen we te werk met een Sentinel-2 beeld van de Braziliaanse stad B\u00e9lem uit 2020. Aangezien de volledige Sentinel-bibliotheek beschikbaar is binnen Earth Engine, kan dit beeld eenvoudig worden ingeladen. Bekijk hiervoor eerst de naam nog eens van je gedownload S2-bestand, bijvoorbeeld: S2B_MSIL1C_ 20200808T134219_N0209_R124_T22MGD _20200808T153444.SAFE In Earth Engine is het vette gedeelte van de filenaam belangrijk. Dit wordt als volgt in earth-engine ingeladen, via 'ee.Image' : //Voorbeeld: Sentinel-2 beeld van vorig practicum var S2_Belem = ee . Image ( 'COPERNICUS/S2_SR/20200808T134219_20200808T134214_T22MGD' ) print ( S2_Belem ) // Zoom in de Map-view in naar het beeld, met Zoom-factor 9 Map . centerObject ( S2_Belem , 9 ); Hiermee werd slechts een variabele aangemaakt die het beeld omvat. Om het beeld te visualiseren wordt gebruik gemaakt van de functie Map.addLayer() : //Visualiseren van het satellietbeeld Map . addLayer ( S2_Belem ); Bij het uitvoeren van bovenstaande code bekomen we een zwart vlak, niet bepaald de visualisatie die we wensen. Bij het uitvoeren van bovenstaande code bekomen we een zwart vlak, niet bepaald de visualisatie die we wensen. Dit komt omdat we nog geen visualisatieparameters hebben aangegeven, waardoor de eerste 3 banden naar de rode, groene en blauwe band respectievelijk worden toegekend en de pixelrange zo groot is dat alle pixels een zwarte kleur krijgen. Om dit manueel aan te passen, zoek je je toegevoegde laag in 'Layers' in de Map-view. Klik op het tandwieltje. Een visualisatie-scherm springt open. Pas de parameters aan, zodat je een normale kleurencomposiet verkrijgt, met een stretch van 3 gamma en druk op 'Apply'. Een visueel beter resultaat wordt verkregen. Handmatig instellen van de visualisatieparameters kan via 'Layers' in de Map view Het is echter niet handig om steeds opnieuw de visualisatie handmatig in te stellen. Gelukkig kan deze ook als code ge\u00efmporteerd worden in GEE (klik op 'Import'). De visualisatieparameters worden toegevoegd in de Imports. Deze kunnen dan in de Map.addLayer() -functie worden meegeven tijdens het visualiseren. In de code-editor zelf kunnen de visualisatieparameters eveneens gedefinieerd worden. // Aanmaken van visualizatieparameters var visualization = { min : 0 , max : 3000 , bands : [ 'B4' , 'B3' , 'B2' ], }; Map . centerObject ( S2_Belem , 9 ); Map . addLayer ( S2_Belem , visualization , 'B\u00e8lem_met_Vis' );","title":"Visualisatie van een enkelvoudig satellietbeeld"},{"location":"P4/P4-ImageVisualization.html#beeldcollecties-zoeken-en-filteren","text":"In voorgaande paragraaf visualiseerden we een Sentinel-2 beeld die we reeds hadden opgezocht waarvan wisten dat de kwaliteit goed zat \u00e9n waarvan we de bestandsnaam reeds kenden. Het is natuurlijk niet handig om steeds een filenaam te moeten kennen om verder te kunnen werken in Earth Engine. Daarmee zouden we ook de geweldige kracht van het programma om doorheen vele petabytes aan Aardobservatiedata te zoeken onbenut laten. In wat volgt gaan we op basis van een locatie op zoek gaan naar geschikte satellietbeelden, door het filteren van gehele beeldcollecties.","title":"Beeldcollecties zoeken en filteren"},{"location":"P4/P4-ImageVisualization.html#area-of-interest-aoi","text":"Starten doen we met het intekenen van een gewenste Area Of Interest (AOI) in de Map View. Een AOI is niets anders dan de afbakening van het studiegebied, waarbinnen we onze data wensen te verkrijgen. Er kan rechtstreeks gezoomd worden naar een locatie via de zoekbalk bovenaan of door het scrollen met de muis. Teken vervolgs een gewenste gebied in door gebruik te maken van de toolknoppen in de \"Map View\": . In dit voorbeeld kiezen we voor de Konigin der badsteden, Oostende, als studiegebied: Automatisch wordt een nieuwe variabele aangemaakt onder de naam 'geometry', welke eenvoudig hernoemd kan worden naar een eenvoudig te gebruiken variabelenaam: Bekijk de eigenschappen van de polygoon door het naar de console te printen: //Polygoon-informatie naar de console schrijven: print ( Oostende )","title":"Area of Interest (AOI)"},{"location":"P4/P4-ImageVisualization.html#datacollecties-filteren-en-visualiseren","text":"Voor deze oefening maken we als afwisseling gebruik van Landsat-8 beelden (zie ook het stukje omtrent de Earth Engine data catalog ). De importeer-code kan gekopieerd worden uit de data catalog en ziet er als volgt uit: var L8 = ee . ImageCollection ( 'LANDSAT/LC08/C01/T1_SR' ) print ( 'Grootte van de L8-collectie :' , L8 . size ()) Hiermee verwijst de variabele 'L8' naar de volledige Landsat-8 collectie (surface reflectance). De '.size()'-functie geeft het aantal beelden dat in deze collectie zijn begrepen. Een hele hoop, sinds ze collectie veel beelden van de volledige aarde omvat. Deze verzameling dient bijgevolg gefilterd te worden. Filteren kan op basis van de metadata: //Filteren o.b.v. datum, locatie: var L8 = L8 . filterDate ( '2020-01-01' , '2020-10-30' ) //Op basis van datum . filterBounds ( Oostende ) //op basis van locatie (de AOI); //Printen van de nieuwe grootte print ( 'L8 size na filtering' , L8 . size ()) // Printen van de collectie voor inspectie print ( 'Filtered collection: ' , L8 ) De beelden in de collectie zijn standaard gesorteerd op datum, indien we dus het bovenste beeld eruit halen, zal dit het eerste Landsat-8 beeld zijn gemaakt in 2020. Met de functie .first() , halen we deze eruit. Print deze naar de console en bekijk het verschil met de de Imagecollectie. // Krijg het eerste (standaard oudste) beeld uit de collectie: var L8_first = L8 . first () print ( 'Eerste Beeld:' , L8_first ) In een volgende stap kunnen we dit beeld ook gaan visualiseren, met javascript Map.addLayer() . 6) Ook nu kunnen we dit als een echte kleurencomposiet visualiseren (voor Landsat 8 betekent dit dus B2 (blauw), B3 (groen) en B4 (rood)). // Landsat-8 visualisatie instellen. var trueColor = { bands : [ 'B4' , 'B3' , 'B2' ], min : 0 , max : 3000 , gamma : 1.4 , }; Map . addLayer ( L8_first , trueColor , 'L8_TrueColorComposite' ) Eerste Landsat 8 beeld binnen de gefilterede collectie Mogelijk is dit eerste beeld niet het meest ideale wat betreft de wolkbedekking, waardoor er weinig te zien valt. Laten we nu op zoek gaan naar het beeld met de laagste wolkenbedekking binnen de collectie. Dit doen we in eerste instantie door de collectie te sorteren volgens het percentage cloudcover, wat standaard tot de metadata van een Landsatbeeld behoort. Bekijk het beeld. Wat valt je op? Wordt het volledige gebied bedekt? //Sorteren van de collectie obv cloud cover var L8_sortedCC = L8 . sort ( 'CLOUD_COVER' , true ); Map . addLayer ( L8_sortedCC . first (), trueColor , 'Least Cloud cover 2020' ) Landsat 8-beeld met laagste wolkbedekking binnen de gefilterede collectie Bekijk op welke dag de sensor dit beeld heeft genomen. Gebruik hiervoor de \u2018inspector\u2019 om de beeldeigenschappen verder te bekijken. De inspector Opdracht Visualiseer in een nieuw script een valse kleurencomposiet van een Sentinel-2 beeld (Tier 1, Surface Reflectance). Neem hierbij Gent als AOI, met een beeld uit de zomer van 2019 met een zo laag mogelijke wolkenbedekking. Voor het sorteren van de wolkenbedekking, zoek je de gepaste eigenschap om op te sorteren. Deze kun je hier vinden. Bewaar je script.","title":"Datacollecties Filteren en Visualiseren"},{"location":"P4/P4-Intro.html","text":"De Google Earth Engine Interface The Google Earth Engine code editor interface. De interface van de Earth Engine code editor is op zich vrij simpel. Er kunnen 5 grote blokken onderscheden worden: Het linkerpaneel, met 3 tabs: Scripts : je eigen bibliotheek met scripts, onder te verdelen in repositories, folders en scripts. Ook de scripts waar je schrijf- en leesrechten hebt kun je hierin terugvinden. Docs : Bevat informatie over de functies die beschikbaar zijn in Earth Engine. Hier kun je snel de functionaliteiten en beschrijving van de input- en outputparameters terugvinden. Assets : oplijsting met de 'assets' die je opgeladen/aangemaakt hebt in Earth Engine. Assets kunnen rasters of vectoren (met bijvoorbeeld trainingsdata of studiegebied). De code editor zelf in het middenpaneel, waar je scripts kunt aanmaken/bewerken, delen en opslaan. Het rechterpaneel, met 3 tabs: De Console : waar eventuele output of foutmeldingen naar geschreven worden. de 'print()'-functie wordt steeds gebruikt om hier informatie te bekijken. De Inspector : hiermee kun je op specifieke pixels in de 'map view' klikken, waarna de overeenkomstige pixelinformatie wordt gevisualiseerd. De Tasks : bevat een oplijsting van de 'exports' die in het script werden aangemaakt (als je bijvoorbeeld een satellietbeeld naar je Google Drive wenst te sturen). Een export moet hier steeds nog manueel gestart worden. De Map View : waar het beeldmateriaal wordt gevisualiseerd. De zoekfunctie waarmee beeldmateriaal beschikbaar binnen de Google Cloud kan worden opgezocht. Earth Engine code: Javascript 101 Google Earth Engine maakt voor zijn code-editor gebruik van Javascript als programmeertaal, maar om vertrouwd te geraken met GEE hoef je geen Javascript-expert te worden. GEE gebruikt namelijk hoofdzakelijk eigen 'classes' en functionaliteiten, waardoor je slechts een basiskennis javascript nodig hebt. Daarom starten we eerst met een spoedcursus Javascript, waarop we onze verdere 'Earth Engine'-magie kunnen bouwen. \"Hello World\" De 'print'-functie Zoals gebruikelijk is bij het leren van een programmeertaal, groeten we de wereld met ons eerste lijntje code. Open https://code.earthengine.google.com/ , en voeg volgend lijntje toe aan het nieuwe script. //Printen van Hello World print ( 'Hello World' ) Klik daarna op 'Run'. Proficiat! Het eerste scriptje is geschreven. Hiermee heb je onmiddellijk ook een eerste uitermate handige functie gezien. De \u2018print\u2019-functie kun je gebruiken om bepaalde informatie naar de Console te schrijven, zoals metadata, ... . Verder valt hieruit ook op te merken dat een dubbele voorwaartse slash '// ' gebruikt wordt om notities te nemen binnen de code. Strings Proficiat! Het eerste scriptje is geschreven. Laat ons deze string nu onderbrengen in een variabele. In Javascript dient een variabele altijd ge\u00efniteerd te worden met var statement. Indien je dit zou weglaten, zal je op een 'error' stoten. //Aanmaken van de variabele 'aString' var aString = 'Hello World' print ( aString ) Om het datatype van de variabele aString na te gaan, kun je dit oproepen met de functie \u2018typeof()\u2019-statement: // Type van de variabele aString naar de Console schrijven print ( typeof ( aString )) Functies In een volgende stap maken we een functie aan, waarbij je een string naar keuze kunt groeten. Een functie in Google Earth Engine ziet er uit volgens volgende opbouw: var functienaam = function ( inputvariabelen ) { //Hier de functie-bewerkingen //output = a + b Return output }; Bijvoorbeeld: //Hello Function: var hello_function = function ( String ) { var goeindag = 'Hello ' + String return goeindag }; //Functie uitvoeren: var hallo = hello_function ( 'Boerekot' ); print ( hallo ) //Variabelen aangemaakt binnen de functie worden enkel daar gebruikt: print ( goeindag ) Lijsten Een lijst in Javascript wordt steeds opgegeven met [ en ]. Een lijstindex begint steeds vanaf '0', waarbij de eerste waarde dus op positie 0 staat. var lievelingsnummers = [ 8 , 6 , 3 , 27 ] print ( 'Eerste lievelingsnummer in de lijst = ' , lievelingsnummers [ 0 ]) //Lijstelementen aanpassen var automerken = [ \"BMW\" , \"Volkswagen\" , \"Minerva\" ] automerken [ 2 ] = [ \"Opel\" ] print ( automerken ) Objecten Een Object wordt aangegeven met '{' en '}'. Aan een object hangen steeds enkele variabelen die tot het object behoren. //object var beelden = { Sensor : \"Sentinel 2\" , Regios : [ \"Belgium\" , \"France\" , \"Vaticano\" ], Aantalbeelden : 2 , 1 : \"Ja\" } Om een eigenschap van een object op te roepen, wordt stees een puntje '.' gebruikt: object.eigenschap. Indien we bijvoorbeeld de sensor van ons aangemaakte beeldmateriaal willen nagaan: // Sensor bekijken print ( beelden . Sensor ) // Andere methode via haakjes [] print ( 'Regios: ' , beelden [ 'Regios' ]) Specifieke Earth Engine objecten ee.Thing Om objecten/elementen/processen richting de google server te sturen, wordt gebruik gemaakt van zogenaamde 'containers'. Om dit aan te duiden wordt gebruik gemaakt van een ee.Thing structuur. Dit zal doorheen de komende practica wat duidelijker worden. ee.Images Een Image is rasterdata bestaande uit \u00e9\u00e9n of meerdere banden, waarvan elke band een eigen naam, datatype, resolutie en projectie heeft. Een enkel Sentinel-2 beeld zoals in Practicum 3 gedownload werd, zal als \u00e9\u00e9n Image kunnen worden opgeslagen. Om een Image in te laden en Earth Engine wordt gebruik gemaakt van ee.Image . In volgend hoofdstuk wordt dit ge\u00efllustreerd. ee.ImageCollections Een ImageCollection is een collectie van meerdere Image 's, zoals bijvoorbeeld de volledige Sentinel-2 collectie. Het bevat m.a.w. heel wat beelden die in een bepaalde volgorde gesorteerd zijn. Standaard is dit o.b.v. datum, maar aangepaste sorteringen zijn eveneens mogelijk, zoals we in een komende oefening gaan zien.","title":"Introductie tot Earth Engine"},{"location":"P4/P4-Intro.html#de-google-earth-engine-interface","text":"The Google Earth Engine code editor interface. De interface van de Earth Engine code editor is op zich vrij simpel. Er kunnen 5 grote blokken onderscheden worden: Het linkerpaneel, met 3 tabs: Scripts : je eigen bibliotheek met scripts, onder te verdelen in repositories, folders en scripts. Ook de scripts waar je schrijf- en leesrechten hebt kun je hierin terugvinden. Docs : Bevat informatie over de functies die beschikbaar zijn in Earth Engine. Hier kun je snel de functionaliteiten en beschrijving van de input- en outputparameters terugvinden. Assets : oplijsting met de 'assets' die je opgeladen/aangemaakt hebt in Earth Engine. Assets kunnen rasters of vectoren (met bijvoorbeeld trainingsdata of studiegebied). De code editor zelf in het middenpaneel, waar je scripts kunt aanmaken/bewerken, delen en opslaan. Het rechterpaneel, met 3 tabs: De Console : waar eventuele output of foutmeldingen naar geschreven worden. de 'print()'-functie wordt steeds gebruikt om hier informatie te bekijken. De Inspector : hiermee kun je op specifieke pixels in de 'map view' klikken, waarna de overeenkomstige pixelinformatie wordt gevisualiseerd. De Tasks : bevat een oplijsting van de 'exports' die in het script werden aangemaakt (als je bijvoorbeeld een satellietbeeld naar je Google Drive wenst te sturen). Een export moet hier steeds nog manueel gestart worden. De Map View : waar het beeldmateriaal wordt gevisualiseerd. De zoekfunctie waarmee beeldmateriaal beschikbaar binnen de Google Cloud kan worden opgezocht.","title":"De Google Earth Engine Interface"},{"location":"P4/P4-Intro.html#earth-engine-code-javascript-101","text":"Google Earth Engine maakt voor zijn code-editor gebruik van Javascript als programmeertaal, maar om vertrouwd te geraken met GEE hoef je geen Javascript-expert te worden. GEE gebruikt namelijk hoofdzakelijk eigen 'classes' en functionaliteiten, waardoor je slechts een basiskennis javascript nodig hebt. Daarom starten we eerst met een spoedcursus Javascript, waarop we onze verdere 'Earth Engine'-magie kunnen bouwen.","title":"Earth Engine code: Javascript 101"},{"location":"P4/P4-Intro.html#hello-world","text":"","title":"\"Hello World\""},{"location":"P4/P4-Intro.html#de-print-functie","text":"Zoals gebruikelijk is bij het leren van een programmeertaal, groeten we de wereld met ons eerste lijntje code. Open https://code.earthengine.google.com/ , en voeg volgend lijntje toe aan het nieuwe script. //Printen van Hello World print ( 'Hello World' ) Klik daarna op 'Run'. Proficiat! Het eerste scriptje is geschreven. Hiermee heb je onmiddellijk ook een eerste uitermate handige functie gezien. De \u2018print\u2019-functie kun je gebruiken om bepaalde informatie naar de Console te schrijven, zoals metadata, ... . Verder valt hieruit ook op te merken dat een dubbele voorwaartse slash '// ' gebruikt wordt om notities te nemen binnen de code.","title":"De 'print'-functie"},{"location":"P4/P4-Intro.html#strings","text":"Proficiat! Het eerste scriptje is geschreven. Laat ons deze string nu onderbrengen in een variabele. In Javascript dient een variabele altijd ge\u00efniteerd te worden met var statement. Indien je dit zou weglaten, zal je op een 'error' stoten. //Aanmaken van de variabele 'aString' var aString = 'Hello World' print ( aString ) Om het datatype van de variabele aString na te gaan, kun je dit oproepen met de functie \u2018typeof()\u2019-statement: // Type van de variabele aString naar de Console schrijven print ( typeof ( aString ))","title":"Strings"},{"location":"P4/P4-Intro.html#functies","text":"In een volgende stap maken we een functie aan, waarbij je een string naar keuze kunt groeten. Een functie in Google Earth Engine ziet er uit volgens volgende opbouw: var functienaam = function ( inputvariabelen ) { //Hier de functie-bewerkingen //output = a + b Return output }; Bijvoorbeeld: //Hello Function: var hello_function = function ( String ) { var goeindag = 'Hello ' + String return goeindag }; //Functie uitvoeren: var hallo = hello_function ( 'Boerekot' ); print ( hallo ) //Variabelen aangemaakt binnen de functie worden enkel daar gebruikt: print ( goeindag )","title":"Functies"},{"location":"P4/P4-Intro.html#lijsten","text":"Een lijst in Javascript wordt steeds opgegeven met [ en ]. Een lijstindex begint steeds vanaf '0', waarbij de eerste waarde dus op positie 0 staat. var lievelingsnummers = [ 8 , 6 , 3 , 27 ] print ( 'Eerste lievelingsnummer in de lijst = ' , lievelingsnummers [ 0 ]) //Lijstelementen aanpassen var automerken = [ \"BMW\" , \"Volkswagen\" , \"Minerva\" ] automerken [ 2 ] = [ \"Opel\" ] print ( automerken )","title":"Lijsten"},{"location":"P4/P4-Intro.html#objecten","text":"Een Object wordt aangegeven met '{' en '}'. Aan een object hangen steeds enkele variabelen die tot het object behoren. //object var beelden = { Sensor : \"Sentinel 2\" , Regios : [ \"Belgium\" , \"France\" , \"Vaticano\" ], Aantalbeelden : 2 , 1 : \"Ja\" } Om een eigenschap van een object op te roepen, wordt stees een puntje '.' gebruikt: object.eigenschap. Indien we bijvoorbeeld de sensor van ons aangemaakte beeldmateriaal willen nagaan: // Sensor bekijken print ( beelden . Sensor ) // Andere methode via haakjes [] print ( 'Regios: ' , beelden [ 'Regios' ])","title":"Objecten"},{"location":"P4/P4-Intro.html#specifieke-earth-engine-objecten","text":"","title":"Specifieke Earth Engine objecten"},{"location":"P4/P4-Intro.html#eething","text":"Om objecten/elementen/processen richting de google server te sturen, wordt gebruik gemaakt van zogenaamde 'containers'. Om dit aan te duiden wordt gebruik gemaakt van een ee.Thing structuur. Dit zal doorheen de komende practica wat duidelijker worden.","title":"ee.Thing"},{"location":"P4/P4-Intro.html#eeimages","text":"Een Image is rasterdata bestaande uit \u00e9\u00e9n of meerdere banden, waarvan elke band een eigen naam, datatype, resolutie en projectie heeft. Een enkel Sentinel-2 beeld zoals in Practicum 3 gedownload werd, zal als \u00e9\u00e9n Image kunnen worden opgeslagen. Om een Image in te laden en Earth Engine wordt gebruik gemaakt van ee.Image . In volgend hoofdstuk wordt dit ge\u00efllustreerd.","title":"ee.Images"},{"location":"P4/P4-Intro.html#eeimagecollections","text":"Een ImageCollection is een collectie van meerdere Image 's, zoals bijvoorbeeld de volledige Sentinel-2 collectie. Het bevat m.a.w. heel wat beelden die in een bepaalde volgorde gesorteerd zijn. Standaard is dit o.b.v. datum, maar aangepaste sorteringen zijn eveneens mogelijk, zoals we in een komende oefening gaan zien.","title":"ee.ImageCollections"},{"location":"P4/P4-Reducing.html","text":"Over Reducing \u2018Reducing\u2019 een beeld- of datacollectie in Google Earth Engine is het proces waarbij de beeldcollectie wordt geaggregeerd over tijd, ruimte, banden, .... In dit proces wordt een beeldcomposiet aangemaakt van de beschikbare beelden in de collectie, waarbij per pixel een bepaalde vooropgestelde waarde wordt gekozen, zoals het min, max, gemiddelde, mediaan,\u2026 De collectie wordt als het ware 'gereduceerd' tot \u00e9\u00e9n enkel visualiseerbaar beeld. Reducing an ImageCollection: principe. Een voorbeeld: neem de eerste pixel van de gefilterde en gesorteerde Landsat 8 collectie L8_sortedCC . Visualiseer het resultaat. Wat valt je op? Is ditmaal het volledige gebied bedekt? // Reducer over de L8_sortedCC collectie, waarbij steeds de eerste pixel genomen wordt. var L8_first_red = L8_sortedCC . reduce ( ee . Reducer . first ()); //Bekijk de eigenschappen van het gereduceerd beeld print ( L8_first_red ) var visParams_first = { bands : [ 'B4_first' , 'B3_first' , 'B2_first' ], min : 0 , max : 3000 , gamma : 1.4 , }; // Visualiseren als een normale kleurencomposiet Map . addLayer ( L8_first_red , visParams_first , 'L8_First pixels' ) Bandbenaming na reducing Let ook, bij het aanroepen van de reducer functie, worden ook de banden hernoemd. Houd hier rekening mee bij het visualiseren. Het eventueel hernoemen van banden kan via de functie .rename() Bandnamen bij de 'First'-gereduceerde collectie. ee.Reducer.first() VS .first() In een eerdere oefening namen we reeds het eerste beeld uit een hele collectie met de .first() functie. Dit is dus niet hetzelfde, gezien een reducer zicht niet beperkt tot \u00e9\u00e9n enkel beeld, maar de volledige collectie gaat reduceren. Shortcut syntax Bepaalde \u2013 veel gebruikte \u2013 reducers hebben ook een zogenaamde \u2018shortcut\u2019 syntax in Earth engine zoals mean() , median() , min() en sum() . Deze shortcut syntax zorgt ervoor dat een collectie eenvoudiger te reduceren is, zonder de hele .reduce()(ee.Reducer.mean()) syntax te moeten gebruiken. Een voorbeeld: //Een Median() Reducer over the Landsat-8 collectie var L8_median = L8 . reduce ( ee . Reducer . median ()); //Of via de short-syntax (geeft zelfde resultaat) var L8_median = L8 . median (); // Visualiseren Map . addLayer ( L8_median , trueColor , 'L8_median' ) Voorbeeld mediane reducer over de L8_sortedCC-collectie Opdracht Probeer enkele van de Reducers uit op je Sentinel-2 collectie van Gent. Bewaar je script.","title":"Reducing ImageCollections"},{"location":"P4/P4-Reducing.html#over-reducing","text":"\u2018Reducing\u2019 een beeld- of datacollectie in Google Earth Engine is het proces waarbij de beeldcollectie wordt geaggregeerd over tijd, ruimte, banden, .... In dit proces wordt een beeldcomposiet aangemaakt van de beschikbare beelden in de collectie, waarbij per pixel een bepaalde vooropgestelde waarde wordt gekozen, zoals het min, max, gemiddelde, mediaan,\u2026 De collectie wordt als het ware 'gereduceerd' tot \u00e9\u00e9n enkel visualiseerbaar beeld. Reducing an ImageCollection: principe. Een voorbeeld: neem de eerste pixel van de gefilterde en gesorteerde Landsat 8 collectie L8_sortedCC . Visualiseer het resultaat. Wat valt je op? Is ditmaal het volledige gebied bedekt? // Reducer over de L8_sortedCC collectie, waarbij steeds de eerste pixel genomen wordt. var L8_first_red = L8_sortedCC . reduce ( ee . Reducer . first ()); //Bekijk de eigenschappen van het gereduceerd beeld print ( L8_first_red ) var visParams_first = { bands : [ 'B4_first' , 'B3_first' , 'B2_first' ], min : 0 , max : 3000 , gamma : 1.4 , }; // Visualiseren als een normale kleurencomposiet Map . addLayer ( L8_first_red , visParams_first , 'L8_First pixels' ) Bandbenaming na reducing Let ook, bij het aanroepen van de reducer functie, worden ook de banden hernoemd. Houd hier rekening mee bij het visualiseren. Het eventueel hernoemen van banden kan via de functie .rename() Bandnamen bij de 'First'-gereduceerde collectie. ee.Reducer.first() VS .first() In een eerdere oefening namen we reeds het eerste beeld uit een hele collectie met de .first() functie. Dit is dus niet hetzelfde, gezien een reducer zicht niet beperkt tot \u00e9\u00e9n enkel beeld, maar de volledige collectie gaat reduceren.","title":"Over Reducing"},{"location":"P4/P4-Reducing.html#shortcut-syntax","text":"Bepaalde \u2013 veel gebruikte \u2013 reducers hebben ook een zogenaamde \u2018shortcut\u2019 syntax in Earth engine zoals mean() , median() , min() en sum() . Deze shortcut syntax zorgt ervoor dat een collectie eenvoudiger te reduceren is, zonder de hele .reduce()(ee.Reducer.mean()) syntax te moeten gebruiken. Een voorbeeld: //Een Median() Reducer over the Landsat-8 collectie var L8_median = L8 . reduce ( ee . Reducer . median ()); //Of via de short-syntax (geeft zelfde resultaat) var L8_median = L8 . median (); // Visualiseren Map . addLayer ( L8_median , trueColor , 'L8_median' ) Voorbeeld mediane reducer over de L8_sortedCC-collectie Opdracht Probeer enkele van de Reducers uit op je Sentinel-2 collectie van Gent. Bewaar je script.","title":"Shortcut syntax"},{"location":"P5/P5-Colormanipulation.html","text":"","title":"P5 Colormanipulation"},{"location":"P5/P5-ImageStatistics.html","text":"Histogram Een histogram is, binnen de remote sensing, een grafische weerave van de statistische frequentie van de pixelwaarden binnen een satellietbeeld. Deze pixelwaarden verspreiden zich tussen de waarden 0 en 255. In een histogram worden deze waarden op de x -as geplot, terwijl de overeenkomstige frequentie voor elke waarde binnen het beeld op de Y-as wordt geplot. In wat volgt maken we een histogram aan van het aangemaakte ndvi-beeld. Hiervoor is steeds een regio (dus polygoon) noodzakelijk, waarvoor een histogram wordt aangemaakt. In een eerste fase doen we dit voor het volledige weerhouden satellietbeeld. Op de geometrie van dit beeld naar earth engine te vertalen naar een polygoon maken we gebruik van de functie .geometry() . var ROI = ndvi . geometry (); Bekijk de resulterende ROI eventueel door deze te mappen met Map.addLayer(ROI) . Uiteraard kun je ook handmatig een polygoon intekenen. Om een histogram aan te maken wordt gebruik gemaakt van de ui.Chart.image.histogram() -functie binnen Earth Engine. Deze functie neemt volgende elementen aan (ook te checken via de 'Docs'): het beeld, de ROI, de schaal waarover de histogram wordt berekend, het aantal te plotten histogrambalkjes. Layout-opties worden afzonderlijk toegekend via .setOptions() . //Initialiseren van een historgram via de ui.Chart functie var ndviHist = ui . Chart . image . histogram ({ image : ndvi , region : ROI , scale : 10 , maxBuckets : 50 , maxPixels : 1e12 }); //Histogram updaten met stijlopties ndviHist = ndviHist . setOptions ({ title : 'Histogram van NDVI in de Gentse Haven' }); //Histogram schrijven naar de console print ( ndviHist ) Parameters meegeven aan een functie Als je parameters meegeeft aan een functie in Javascript, kun je dit op 2 manieren doen: De (noodzakelijke) parameters meegeven in volgorde aan de functie. Bijvoorbeeld: ui.Chart.image.histogram(ndvi, ROI, 10, 50) . Hierbij is het noodzakelijk dat de paramters in juist volgorde worden meegeven en er geen parameters worden overgeslagen. Opstellen van een dictionary , waarbij de parameters expliciet worden toegekend, zoals in het voorbeeld hierboven. Dit zorgt voor wat extra overzicht. var ndviHist = ui . Chart . image . histogram ({ image : ndvi , region : ROI , scale : 10 , maxBuckets : 50 , maxPixels : 1e12 }); NDVI Histogram van Haven Gent/Vlaanderen Als je kijkt naar het resulterend histogram, dan kun je enkele pieken opmerken: rond -0.3, rond 0.1 en rond 0.8. Verklaar de oorsprong van deze pieken. Bandstatistieken Om beeldstatistieken binnen een bepaalde ROI te berekenen binnen Earth Engine wordt gebruik gemaakt van image.reduceRegion() . Het principe van deze 'beeldreducer' is hetzelfde als een recuder van een ImageCollection , met dat verschil dat de pixels binnen een regio van eenzelfde beeld worden gereduceerd, zoals in onderstaande figuur wordt ge\u00efllustreerd. Hiermee kan m.a.w. - binnen een bepaalde ROI - bepaalde statistieken berekend worden, zoals het minimum, gemiddelde pixelwaarde, maximum, mediane waarde, ... Illustratie van een Reducer toegepast op een beeld (Image) binnen een bepaalde regio. //Statistieken van NDVI: Toepassen van een Reducer var ndvi_mean = ndvi . reduceRegion ({ reducer : ee . Reducer . mean (), geometry : ROI , scale : 10 , maxPixels : 1e12 }); print ( 'Gemiddelde NDVI-waarde' , ndvi_mean )","title":"Beeldstatistieken"},{"location":"P5/P5-ImageStatistics.html#histogram","text":"Een histogram is, binnen de remote sensing, een grafische weerave van de statistische frequentie van de pixelwaarden binnen een satellietbeeld. Deze pixelwaarden verspreiden zich tussen de waarden 0 en 255. In een histogram worden deze waarden op de x -as geplot, terwijl de overeenkomstige frequentie voor elke waarde binnen het beeld op de Y-as wordt geplot. In wat volgt maken we een histogram aan van het aangemaakte ndvi-beeld. Hiervoor is steeds een regio (dus polygoon) noodzakelijk, waarvoor een histogram wordt aangemaakt. In een eerste fase doen we dit voor het volledige weerhouden satellietbeeld. Op de geometrie van dit beeld naar earth engine te vertalen naar een polygoon maken we gebruik van de functie .geometry() . var ROI = ndvi . geometry (); Bekijk de resulterende ROI eventueel door deze te mappen met Map.addLayer(ROI) . Uiteraard kun je ook handmatig een polygoon intekenen. Om een histogram aan te maken wordt gebruik gemaakt van de ui.Chart.image.histogram() -functie binnen Earth Engine. Deze functie neemt volgende elementen aan (ook te checken via de 'Docs'): het beeld, de ROI, de schaal waarover de histogram wordt berekend, het aantal te plotten histogrambalkjes. Layout-opties worden afzonderlijk toegekend via .setOptions() . //Initialiseren van een historgram via de ui.Chart functie var ndviHist = ui . Chart . image . histogram ({ image : ndvi , region : ROI , scale : 10 , maxBuckets : 50 , maxPixels : 1e12 }); //Histogram updaten met stijlopties ndviHist = ndviHist . setOptions ({ title : 'Histogram van NDVI in de Gentse Haven' }); //Histogram schrijven naar de console print ( ndviHist ) Parameters meegeven aan een functie Als je parameters meegeeft aan een functie in Javascript, kun je dit op 2 manieren doen: De (noodzakelijke) parameters meegeven in volgorde aan de functie. Bijvoorbeeld: ui.Chart.image.histogram(ndvi, ROI, 10, 50) . Hierbij is het noodzakelijk dat de paramters in juist volgorde worden meegeven en er geen parameters worden overgeslagen. Opstellen van een dictionary , waarbij de parameters expliciet worden toegekend, zoals in het voorbeeld hierboven. Dit zorgt voor wat extra overzicht. var ndviHist = ui . Chart . image . histogram ({ image : ndvi , region : ROI , scale : 10 , maxBuckets : 50 , maxPixels : 1e12 }); NDVI Histogram van Haven Gent/Vlaanderen Als je kijkt naar het resulterend histogram, dan kun je enkele pieken opmerken: rond -0.3, rond 0.1 en rond 0.8. Verklaar de oorsprong van deze pieken.","title":"Histogram"},{"location":"P5/P5-ImageStatistics.html#bandstatistieken","text":"Om beeldstatistieken binnen een bepaalde ROI te berekenen binnen Earth Engine wordt gebruik gemaakt van image.reduceRegion() . Het principe van deze 'beeldreducer' is hetzelfde als een recuder van een ImageCollection , met dat verschil dat de pixels binnen een regio van eenzelfde beeld worden gereduceerd, zoals in onderstaande figuur wordt ge\u00efllustreerd. Hiermee kan m.a.w. - binnen een bepaalde ROI - bepaalde statistieken berekend worden, zoals het minimum, gemiddelde pixelwaarde, maximum, mediane waarde, ... Illustratie van een Reducer toegepast op een beeld (Image) binnen een bepaalde regio. //Statistieken van NDVI: Toepassen van een Reducer var ndvi_mean = ndvi . reduceRegion ({ reducer : ee . Reducer . mean (), geometry : ROI , scale : 10 , maxPixels : 1e12 }); print ( 'Gemiddelde NDVI-waarde' , ndvi_mean )","title":"Bandstatistieken"},{"location":"P5/P5-Intro.html","text":"In Practicum 5 bouwen we verder op de aangeleerde zaken uit Practicum 4. Met de beelden die we uit de `ImageCollections halen, gaan we statistieken halen, indices bereken en handelingen uitvoeren om informatie te benadrukken. Als slot behandelen we methodieken om een Principale Compentenanalyse (PCA) uit te voeren op de (multidimensionale) beelden.","title":"Intro"},{"location":"P5/P5-PCA.html","text":"De Principale componentenanalyse Een principale componentenanalyse (PCA) is een lineaire transformatie waarbij de banden worden gezocht die het meeste informatie bevatten. Veelal wordt deze gebruikt om processingtijd van grote datasets te beperken, zoals vaak bij hyperspectrale beelden het geval is. Het achterliggende principe is dat de verschillende spectrale banden van een sensor vaak informatie dragen die (gedeeltelijk) gecorreleerd zijn aan elkaar, waardoor er sprake is van onnodige of dubbele informatie. PCA zorgt voor een transformatie van de multispectrale data zodat nieuwe variabelen niet meer of amper met elkaar gecorreleerd zijn. Principe van PCA voor een dataset met 2 banden (rood en groen) die met elkaar gecorreleerd zijn. Een PCA werd uitgevoerd, bestaande uit een translate (van o naar o\u2019) en een rotatie zodoende dat de er 2 nieuwe variabelen ontstaan (PC1 en PC2). De eerste principale component wordt dus gevonden door de richting in de data waar het meeste variatie te vinden is en bijgevolg de meeste data. De 2e principale component komt hier loodrecht op te staan. Het spreekt voor zich dit dit in een 2-dimensionale ruimte zoals in bovenstaande figuur eenvoudig is, maar dit kan eveneens worden toegepast in een meer-dimensionale dataset (zoals bijvoorbeeld een Sentinel-2 beeld met 12 banden). Mathematisch gezien kan een PCA worden gezien als een zoektocht naar een translatie en rotatie van de multidimensionale dataset, waardoor de covariantiematrix van de dataset een diagonale matrix wordt na transformatie. In andere woorden, elke nieuwe variabele is gecorreleerd met zichzelf en niet meer met de andere variabele. De eigenwaarden en eigenvectoren van de originele covariantiematrix worden dus berekend. Elke eigenwaarde met de geassocieerde eigenvector beschrijven dan de nieuwe principale component, waarbij de eigenvector de richting geeft van de nieuwe component en de eigenwaarde als een proxy dient voor de hoeveel informatie dat de component bevat. (voor de specifieke wiskundige details kan worden verwezen naar de cursus van Wiskunde 1 (Lineaire algebra) of naar deze 5-minuten durende opfrissing. . In Earth Engine is het relatief eenvoudig om de PCA-berekeningen door te voeren. Open een Nieuw Script: 'PC5-PCA' We nemen opnieuw het Sentinel-2 beeld uit Belem. Aangezien enkel de banden B2, B3, B4, B5, B6, B6, B8, B8A, B11 en B12 relevant zijn voor verdere analyse, weerwhouden we enkel deze banden met de functie .select() . //Importeren van het Sentinel-2 beeld van Belem var S2_Belem = ee . Image ( 'COPERNICUS/S2_SR/20200808T134219_20200808T134214_T22MGD' ) //Enkel banden relevant voor de PCA weerhouden in de Image var bands = [ 'B2' , 'B3' , 'B4' , 'B5' , 'B6' , 'B7' , 'B8' , 'B8A' , 'B11' , 'B12' ]; var S2_Belem = S2_Belem . select ( bands ) Opstellen van de PCA-functie (met bijhorende 'helper'-functie) //PCA FUNCTIE var getPrincipalComponents = function ( centered , scale , region ) { // Collapse the bands of the image into a 1D array per pixel. var arrays = centered . toArray (); // Berekenen van de covariantie a.d.h.v. een reduceRegion var covar = arrays . reduceRegion ({ reducer : ee . Reducer . centeredCovariance (), geometry : region , scale : scale , maxPixels : 1e9 }); // Get the 'array' covariance result and cast to an array. // This represents the band-to-band covariance within the region. var covarArray = ee . Array ( covar . get ( 'array' )); // Perform an eigen analysis and slice apart the values and vectors. var eigens = covarArray . eigen (); print ( eigens ) // eigenValues is a P-length vector of Eigenvalues. var eigenValues = eigens . slice ( 1 , 0 , 1 ); // This is a PxP matrix with eigenvectors in rows. var eigenVectors = eigens . slice ( 1 , 1 ); // Convert the array image to 2D arrays for matrix computations. var arrayImage = arrays . toArray ( 1 ); // Left multiply the image array by the matrix of eigenvectors. var principalComponents = ee . Image ( eigenVectors ). matrixMultiply ( arrayImage ); // Turn the square roots of the Eigenvalues into a P-band image. var sdImage = ee . Image ( eigenValues . sqrt ()) . arrayProject ([ 0 ]). arrayFlatten ([ getNewBandNames ( 'sd' )]); // Turn the PCs into a P-band image, normalized by SD. return principalComponents // Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) // Make the one band array image a multi-band image, [] -> ima .arrayFlatten([getNewBandNames('pc')]) // Normalize the PCs by their SDs. . divide ( sdImage ); }; // // De PCAfunctie heeft noog aan een helper-functie, dat een lijst met nieuwe bandnamen samenstelt var getNewBandNames = function ( prefix ) { var seq = ee . List . sequence ( 1 , bandNames . length ()); return seq . map ( function ( b ) { return ee . String ( prefix ). cat ( ee . Number ( b ). int ()); }); }; Toepassen van de PCA-functie. Hiervoor dienen eerst enkele inputparameters met informatie worden aangemaakt /* DE PCA-functie is opgesteld. In wat volgt kunnen we deze toepassen */ // Set some information about the input to be used later. var scale = 30 ; //(30m om processingtijd wat te verminderen => sentinel2 kan tot 10m) var bandNames = S2_Belem . bandNames (); var region = S2_Belem . geometry (); // We nemen de regio van het volledige beeld De gebruikte PCA-functie heeft een 'mean centered' beeld nodig. Dit betekend dat het gemiddelde per band de nieuwe '0-waarde' wordt en elke pixel een waarde krijgt relatief aan deze 0-waarde. Dit zorgt voor een snellere covariantie-berekening. // Mean center the data to enable a faster covariance reducer // and an SD stretch of the principal components. var meanDict = S2_Belem . reduceRegion ({ reducer : ee . Reducer . mean (), geometry : region , scale : scale , maxPixels : 1e12 }); var means = ee . Image . constant ( meanDict . values ( bandNames )); print ( means , 'Gemiddeldes per band' ) var centered = image . subtract ( means ); print ( centered , 'Mean centered Image' ) 6. Vervolgens kunnen we de PCA-functie toepassen // Uitvoeren van de PCA-functie => resultaat is beeld met PC's als nieuwe banden var pcaImage = getPrincipalComponents ( centered , scale , region ); //Bekijken van pcaImage print ( pcaImage ) 7. De resulterende Image , pcaImage is een beeld met als banden de berekende principale componenten. Via een for -lus kunnen we elk deze banden ook in 1x plotten naar de MA // Plot each PC as a new layer for ( var i = 0 ; i < bandNames . length (). getInfo (); i ++ ) { var band = pcImage . bandNames (). get ( i ). getInfo (); Map . addLayer ( pcImage . select ([ band ]), { min : - 2 , max : 2 }, band ); } Resultaten: Principale Component 1 Principale Component 2 Principale Component 3","title":"Principale componenten analyse"},{"location":"P5/P5-PCA.html#de-principale-componentenanalyse","text":"Een principale componentenanalyse (PCA) is een lineaire transformatie waarbij de banden worden gezocht die het meeste informatie bevatten. Veelal wordt deze gebruikt om processingtijd van grote datasets te beperken, zoals vaak bij hyperspectrale beelden het geval is. Het achterliggende principe is dat de verschillende spectrale banden van een sensor vaak informatie dragen die (gedeeltelijk) gecorreleerd zijn aan elkaar, waardoor er sprake is van onnodige of dubbele informatie. PCA zorgt voor een transformatie van de multispectrale data zodat nieuwe variabelen niet meer of amper met elkaar gecorreleerd zijn. Principe van PCA voor een dataset met 2 banden (rood en groen) die met elkaar gecorreleerd zijn. Een PCA werd uitgevoerd, bestaande uit een translate (van o naar o\u2019) en een rotatie zodoende dat de er 2 nieuwe variabelen ontstaan (PC1 en PC2). De eerste principale component wordt dus gevonden door de richting in de data waar het meeste variatie te vinden is en bijgevolg de meeste data. De 2e principale component komt hier loodrecht op te staan. Het spreekt voor zich dit dit in een 2-dimensionale ruimte zoals in bovenstaande figuur eenvoudig is, maar dit kan eveneens worden toegepast in een meer-dimensionale dataset (zoals bijvoorbeeld een Sentinel-2 beeld met 12 banden). Mathematisch gezien kan een PCA worden gezien als een zoektocht naar een translatie en rotatie van de multidimensionale dataset, waardoor de covariantiematrix van de dataset een diagonale matrix wordt na transformatie. In andere woorden, elke nieuwe variabele is gecorreleerd met zichzelf en niet meer met de andere variabele. De eigenwaarden en eigenvectoren van de originele covariantiematrix worden dus berekend. Elke eigenwaarde met de geassocieerde eigenvector beschrijven dan de nieuwe principale component, waarbij de eigenvector de richting geeft van de nieuwe component en de eigenwaarde als een proxy dient voor de hoeveel informatie dat de component bevat. (voor de specifieke wiskundige details kan worden verwezen naar de cursus van Wiskunde 1 (Lineaire algebra) of naar deze 5-minuten durende opfrissing. . In Earth Engine is het relatief eenvoudig om de PCA-berekeningen door te voeren. Open een Nieuw Script: 'PC5-PCA' We nemen opnieuw het Sentinel-2 beeld uit Belem. Aangezien enkel de banden B2, B3, B4, B5, B6, B6, B8, B8A, B11 en B12 relevant zijn voor verdere analyse, weerwhouden we enkel deze banden met de functie .select() . //Importeren van het Sentinel-2 beeld van Belem var S2_Belem = ee . Image ( 'COPERNICUS/S2_SR/20200808T134219_20200808T134214_T22MGD' ) //Enkel banden relevant voor de PCA weerhouden in de Image var bands = [ 'B2' , 'B3' , 'B4' , 'B5' , 'B6' , 'B7' , 'B8' , 'B8A' , 'B11' , 'B12' ]; var S2_Belem = S2_Belem . select ( bands ) Opstellen van de PCA-functie (met bijhorende 'helper'-functie) //PCA FUNCTIE var getPrincipalComponents = function ( centered , scale , region ) { // Collapse the bands of the image into a 1D array per pixel. var arrays = centered . toArray (); // Berekenen van de covariantie a.d.h.v. een reduceRegion var covar = arrays . reduceRegion ({ reducer : ee . Reducer . centeredCovariance (), geometry : region , scale : scale , maxPixels : 1e9 }); // Get the 'array' covariance result and cast to an array. // This represents the band-to-band covariance within the region. var covarArray = ee . Array ( covar . get ( 'array' )); // Perform an eigen analysis and slice apart the values and vectors. var eigens = covarArray . eigen (); print ( eigens ) // eigenValues is a P-length vector of Eigenvalues. var eigenValues = eigens . slice ( 1 , 0 , 1 ); // This is a PxP matrix with eigenvectors in rows. var eigenVectors = eigens . slice ( 1 , 1 ); // Convert the array image to 2D arrays for matrix computations. var arrayImage = arrays . toArray ( 1 ); // Left multiply the image array by the matrix of eigenvectors. var principalComponents = ee . Image ( eigenVectors ). matrixMultiply ( arrayImage ); // Turn the square roots of the Eigenvalues into a P-band image. var sdImage = ee . Image ( eigenValues . sqrt ()) . arrayProject ([ 0 ]). arrayFlatten ([ getNewBandNames ( 'sd' )]); // Turn the PCs into a P-band image, normalized by SD. return principalComponents // Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) // Make the one band array image a multi-band image, [] -> ima .arrayFlatten([getNewBandNames('pc')]) // Normalize the PCs by their SDs. . divide ( sdImage ); }; // // De PCAfunctie heeft noog aan een helper-functie, dat een lijst met nieuwe bandnamen samenstelt var getNewBandNames = function ( prefix ) { var seq = ee . List . sequence ( 1 , bandNames . length ()); return seq . map ( function ( b ) { return ee . String ( prefix ). cat ( ee . Number ( b ). int ()); }); }; Toepassen van de PCA-functie. Hiervoor dienen eerst enkele inputparameters met informatie worden aangemaakt /* DE PCA-functie is opgesteld. In wat volgt kunnen we deze toepassen */ // Set some information about the input to be used later. var scale = 30 ; //(30m om processingtijd wat te verminderen => sentinel2 kan tot 10m) var bandNames = S2_Belem . bandNames (); var region = S2_Belem . geometry (); // We nemen de regio van het volledige beeld De gebruikte PCA-functie heeft een 'mean centered' beeld nodig. Dit betekend dat het gemiddelde per band de nieuwe '0-waarde' wordt en elke pixel een waarde krijgt relatief aan deze 0-waarde. Dit zorgt voor een snellere covariantie-berekening. // Mean center the data to enable a faster covariance reducer // and an SD stretch of the principal components. var meanDict = S2_Belem . reduceRegion ({ reducer : ee . Reducer . mean (), geometry : region , scale : scale , maxPixels : 1e12 }); var means = ee . Image . constant ( meanDict . values ( bandNames )); print ( means , 'Gemiddeldes per band' ) var centered = image . subtract ( means ); print ( centered , 'Mean centered Image' ) 6. Vervolgens kunnen we de PCA-functie toepassen // Uitvoeren van de PCA-functie => resultaat is beeld met PC's als nieuwe banden var pcaImage = getPrincipalComponents ( centered , scale , region ); //Bekijken van pcaImage print ( pcaImage ) 7. De resulterende Image , pcaImage is een beeld met als banden de berekende principale componenten. Via een for -lus kunnen we elk deze banden ook in 1x plotten naar de MA // Plot each PC as a new layer for ( var i = 0 ; i < bandNames . length (). getInfo (); i ++ ) { var band = pcImage . bandNames (). get ( i ). getInfo (); Map . addLayer ( pcImage . select ([ band ]), { min : - 2 , max : 2 }, band ); } Resultaten: Principale Component 1 Principale Component 2 Principale Component 3","title":"De Principale componentenanalyse"},{"location":"P5/P5-Spectral_indices.html","text":"Spectral indices Spectral indices zijn combinaties van 2 of meerdere spectrale banden die gebruikt worden om bepaalde features extra in de verf te zetten of ze te herberekenen naar een relatieve schaal. NDVI De meest gebruikte index is de Normalized Difference Vegatation Index (NDVI) , en wordt berekend als: NDVI = { NIR - RED \\over NIR + RED}. Waarbij: NIR = reflectie in het nabij-infrarode gebied van het spectrum (oftwel Near-Infrared) RED = reflectie in het rode gebied van het spectrum De resulterende index krijgt waarden binnen tussen -1 en 1. Volgens deze formule is de densiteit van vegetatie (NDVI) op een gegeven plaats in het beeld gelijk aan de verschillen in intensiteit van het gereflecteerde licht in het rood en infrarode deel van het spectrum, gedeeld door de soms van deze intensiteiten. Vegetatie absorbeert immers een groot deel van het zichtbare licht ten behoeve van de fotosynthese (dus lage Rood-reflectie), maar weerkaatst vrijwel al het infrarode licht (hoge IR-reflectiewaarde), waardoor de ndvi stijgt. Hoe denser de vegetatie, hoe hoger de ndvi. Andere lichamen, zoals water, observeren IR dan weer beter tot zeer goed, waardoor de ndvi daalt. In Earth Engine kan de NDVI op verschillende manieren berekend worden. We starten met de \u2018meest conventionele\u2019. We starten deze oefening in de Gentse haven. Maal een puntsymbool aan ergens ter hoogte van de Gentse haven in Evergem. Importeer de Sentinel-2 Surface Reflectance (Tier 1) collection en zoek naar het beeld met de laagste wolkbedekking uit 2019 in de periode mei-juni (= de late lente). Bekijk van welke datum het beeld afkomstig is. Visualiseer als een valse kleurencomposiet //1. Importeren van de Sentinel-2 collectie. var S2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); //Filteren op basis van datum (lente 2019) + beeld met laagste wolkenpercentage selecteren var S2_Gent_Lente19 = S2 . filterBounds ( HavenGent ) . filterDate ( '2019-03-20' , '2019-06-30' ) . sort ( 'CLOUDY_PIXEL_PERCENTAGE' ) . first (); print ( 'Gent_Lente19:' , S2_Gent_Lente19 ) //Visualisatieparameters (of handmatig instellen) var S2_ValseKleuren = { gamma : 2 , min : 275 , max : 2088 , bands : [ 'B8' , 'B4' , 'B3' ], }; //Toevoegen aan Map Map . addLayer ( S2_Gent_Lente19 , S2_ValseKleuren , 'Valse Kleuren lente 2019' ) Een eerste methode om een NDVI aan te maken is via de ingebouwde .normalizedDifference() functie. Ga na welke Sentinel-2 banden je nodig hebt om de ndvi te berekenen. (Maak eventueel gebruik van de \u2018Docs\u2019-tab.) //2. Aanmaken NDVI via NormalDifference()-functie. Vul de '?' in var ndvi = S2_Gent_Lente19 . normalizedDifference ([ '?' , '?' ]). rename ( 'NDVI' ); Map . addLayer ( ndvi ,{}, 'ndvi_lente_2019' ) //Zonder visualisatieparametes Een ndvi wordt meestal afgebeeld met een kleurenschema, zoals onderstaand voorbeeld: // Met visualisatie var ndviParams = { min : - 1 , max : 1 , palette : [ 'red' , 'yellow' , 'darkgreen' ]}; Map . addLayer ( ndvi , ndviParams , 'ndvi_2019_vis' ); Oefening: Connecteer de ndvi-waarden met de gepaste landbedekkingsklasse. NDVI waarde Landbedekking (Lente) Negative values (< 0) rocks, bare soil, clouds Small values (0.1 or less) shrubs and meadows Moderate values (0.2 to 0.3) temperate and tropical forests Large values (0.6 to 0.8) (clouds,) water and snow Antwoord NDVI waarde Landbedekking (Lente) Negative values (< 0) clouds, water and snow Small values (0.1 or less) rocks and bare soil Moderate values (0.2 to 0.3) shrubs and meadows Large values (0.6 to 0.8) temperate and tropical forests Band Math (bandbewerkingen) Bandbewerkingen kunnen worden gebruikt om een nieuw beeld aan te maken van de reeds bestaande banden. Het berekenen van indices zoals de NDVI, is al een treffend voorbeeld hiervan. Andere mogelijkheden zijn ratio\u2019s, het verschil van 2 beelden op 2 verschillende tijdstippen om mogelijke veranderingen visueel te benadrukken, \u2026 Er zijn 2 manieren om in Earth Engine een bewerking uit te voeren. Bewerkingen via operatoren De basisoperators maken gebruik van 2 inputs: ofwel 2 beelden, ofwel 1 beeld en 1 constante. De bewerkingen worden steeds per pixel en per band uitgevoerd. Voorbeeld van operatoren zijn add() , subtract() en divide() . //NDVI berekenen aan de hand van bandwerkingen met operatoren // Lange uitwerking: noodzakelijke banden eerst selecteren en onderbrengen in een nieuwe variabele var nir = S2_Gent_Lente19 . select ( 'B8' ); var red = S2_Gent_Lente19 . select ( 'B4' ); var ndvi2 = nir . subtract ( red ). divide ( nir . add ( red )). rename ( 'NDVI' ); Map . addLayer ( ndvi2 , ndviParams , 'ndvi via operatoren' ); Het resultaat is logischerwijs identiek als de voorgaande ndvi-berekening. Bewerkingen via expressies Het spreekt voor zich dat bovenstaande methode voor complex wiskundige bewerkingen niet handig is. Voor dergelijke bewerkingen wordt aangeraden om gebruik te maken van image.expression() , gezien de inputvariabelen hier afzonderlijk worden aangegeven, waardoor de bewerking gemakkelijker wordt weergegeven en het coderen zo vereenvoudigd wordt. De expressie aanvaardt tevens ook constanten. Variabelen die binnen de expressie worden gebruikt, moeten steeds worden aangegeven, zoals in onderstaande NDVI-berekening; //NDVI aan de hand van een expressie var ndvi3 = SS2_Gent_Lente19 . expression ( '(NIR - RED)/(NIR + RED)' , { 'NIR' : S2_Gent_Lente19 . select ( 'B8' ), 'RED' : S2_Gent_Lente19 . select ( 'B4' ) }); Ook hier is het resultaat hetzelfde als de vorige ndvi-berekeningen. Gebruikte operators binnen expressies Onderstaande tabel geeft de binnen de expressies gehanteerde operators weer (bron: Earth Engine guide ) Andere indices Naast de NDVI bestaan er nog een heleboel andere indices, elk met een eigen toepassing. De Normalized Difference Water Index (NDWI) Er bestaan 2 indices met de naam 'NDWI', beiden gerelateerd aan water: De NDWI ontwikkeld door Gao (1996) , als index voor het watergehalte van vegetatie. De Index is gebaseerd op de NIR (gevoelig voor vegetatie) en SWIR (gevoelig voor water) banden: NDWI = { NIR - SWIR \\over NIR + SWIR}. De NDWI ontwikkeld door McFeeters (1996) , als index voor het verscherpen van verschillen in waterlichamen; NDWI = { GREEN - NIR \\over GREEN + NIR}. Opdracht NDWI Test beide NDWI-indices uit op het Sentinel-beeld van de Gentse Haven en omstreken. Bekijk de verschillen. Kijk hiervoor zeker naar naburige natuurgebieden en waterplassen. Opdrachten NDVI voor elk seizoen Maak een wolkenvrije beeldencollectie aan (via 30%-'CLOUDY_PIXEL_PERCENTAGE'-filter + een cloudmask toepassen) aan van de regio Durbuy binnen volgende periodes. Gebruik onderstaande Cloudmask-functie: function maskS2clouds ( image ) { var qa = image . select ( 'QA60' ); // Bits 10 and 11 are clouds and cirrus, respectively. var cloudBitMask = 1 << 10 ; var cirrusBitMask = 1 << 11 ; // Both flags should be set to zero, indicating clear conditions. var mask = qa . bitwiseAnd ( cloudBitMask ). eq ( 0 ) . and ( qa . bitwiseAnd ( cirrusBitMask ). eq ( 0 )); return image . updateMask ( mask ); } 2. Maak een functie aan om de NDVI te berekenen. Laat de functie dan los op de Imagecollectie via .map() . Maak aan de hand van de collectie 3 beelden aan met een median() -reducer, binnen volgende periodes: A. Jan-Februari (Winter) B. April-Mei (Lente) C. Juli-Augustus (Zomer) Visualiseer voor elk seizoen een Normale Kleurencomposiet en een NDVI-beeld. Gebruik onderstaande visualisatieparameters bij het plotten: //Visualisatieparameters instellen var NormaleKleuren = { min : 0 , max : 1500 , bands : [ 'B4' , 'B3' , 'B2' ], }; var ndviParams = { min : 0 , max : 1 , bands : [ 'NDVI' ], palette : [ 'red' , 'yellow' , 'darkgreen' ] }; EXTRA OEF 2- De Enhanced Vegetation Index (EVI): De EVI is gelijkaardig aan de NDVI daar het gebruikt wordt om de aanwezigheid (of \u2018greenness\u2019) van vegetatie a.d.h.v. satellietbeelden te kwantificeren. Het werd ontwikkeld om aan enkele \u201climitaties\u201d van de ndvi te voldoen: EVI is gevoeliger voor gebieden met hogere biomassa EVI reduceert de invloed van de atmosferische condities EVI corrigeert de \u2018canopy background noise\u2019 , die bij NDVI voorkomt De EVI wordt berekend als volgt: EVI = G * {NIR - R \\over NIR + C1 * RED \u2013 C2*BLUE + L}. (waarbij G : een versterkende constante, C1,C2 co\u00ebfficienten en L een \u2018canopy background adjusment factor\u2019 ) Voor Sentinel 2, wordt deze formule: EVI_{S2} = 2.5 * {B8 - B4 \\over B8 + 6 * B4 \u2013 7.5*B2 + 1}. EXTRA: Toevoegen van een legende Om een overzichtelijke legende toe te voegen aan je kaart, kun je onderstaande code gebruiken. Hiermee voeg je een legendepaneel toe voor continue ndvi-data. //------------------------- /* LEGENDE TOEVOEGEN */ //------------------------- // set position of panel var legend = ui . Panel ({ style : { position : 'bottom-left' , padding : '8px 15px' } }); // Create legend title var legendTitle = ui . Label ({ value : 'ndvi' , style : { fontWeight : 'bold' , fontSize : '18px' , margin : '0 0 4px 0' , padding : '0' } }); // Add the title to the panel legend . add ( legendTitle ); // create the legend image var lon = ee . Image . pixelLonLat (). select ( 'latitude' ); var gradient = lon . multiply (( ndviParams . max - ndviParams . min ) / 100.0 ). add ( ndviParams . min ); var legendImage = gradient . visualize ( ndviParams ); // create text on top of legend var panel = ui . Panel ({ widgets : [ ui . Label ( ndviParams [ 'max' ]) ], }); legend . add ( panel ); // create thumbnail from the image var thumbnail = ui . Thumbnail ({ image : legendImage , params : { bbox : '0,0,10,100' , dimensions : '10x200' }, style : { padding : '1px' , position : 'bottom-center' } }); // add the thumbnail to the legend legend . add ( thumbnail ); // create text on top of legend var panel = ui . Panel ({ widgets : [ ui . Label ( ndviParams [ 'min' ]) ], }); legend . add ( panel ); Map . add ( legend );","title":"Spectrale indices"},{"location":"P5/P5-Spectral_indices.html#spectral-indices","text":"Spectral indices zijn combinaties van 2 of meerdere spectrale banden die gebruikt worden om bepaalde features extra in de verf te zetten of ze te herberekenen naar een relatieve schaal.","title":"Spectral indices"},{"location":"P5/P5-Spectral_indices.html#ndvi","text":"De meest gebruikte index is de Normalized Difference Vegatation Index (NDVI) , en wordt berekend als: NDVI = { NIR - RED \\over NIR + RED}. Waarbij: NIR = reflectie in het nabij-infrarode gebied van het spectrum (oftwel Near-Infrared) RED = reflectie in het rode gebied van het spectrum De resulterende index krijgt waarden binnen tussen -1 en 1. Volgens deze formule is de densiteit van vegetatie (NDVI) op een gegeven plaats in het beeld gelijk aan de verschillen in intensiteit van het gereflecteerde licht in het rood en infrarode deel van het spectrum, gedeeld door de soms van deze intensiteiten. Vegetatie absorbeert immers een groot deel van het zichtbare licht ten behoeve van de fotosynthese (dus lage Rood-reflectie), maar weerkaatst vrijwel al het infrarode licht (hoge IR-reflectiewaarde), waardoor de ndvi stijgt. Hoe denser de vegetatie, hoe hoger de ndvi. Andere lichamen, zoals water, observeren IR dan weer beter tot zeer goed, waardoor de ndvi daalt. In Earth Engine kan de NDVI op verschillende manieren berekend worden. We starten met de \u2018meest conventionele\u2019. We starten deze oefening in de Gentse haven. Maal een puntsymbool aan ergens ter hoogte van de Gentse haven in Evergem. Importeer de Sentinel-2 Surface Reflectance (Tier 1) collection en zoek naar het beeld met de laagste wolkbedekking uit 2019 in de periode mei-juni (= de late lente). Bekijk van welke datum het beeld afkomstig is. Visualiseer als een valse kleurencomposiet //1. Importeren van de Sentinel-2 collectie. var S2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); //Filteren op basis van datum (lente 2019) + beeld met laagste wolkenpercentage selecteren var S2_Gent_Lente19 = S2 . filterBounds ( HavenGent ) . filterDate ( '2019-03-20' , '2019-06-30' ) . sort ( 'CLOUDY_PIXEL_PERCENTAGE' ) . first (); print ( 'Gent_Lente19:' , S2_Gent_Lente19 ) //Visualisatieparameters (of handmatig instellen) var S2_ValseKleuren = { gamma : 2 , min : 275 , max : 2088 , bands : [ 'B8' , 'B4' , 'B3' ], }; //Toevoegen aan Map Map . addLayer ( S2_Gent_Lente19 , S2_ValseKleuren , 'Valse Kleuren lente 2019' ) Een eerste methode om een NDVI aan te maken is via de ingebouwde .normalizedDifference() functie. Ga na welke Sentinel-2 banden je nodig hebt om de ndvi te berekenen. (Maak eventueel gebruik van de \u2018Docs\u2019-tab.) //2. Aanmaken NDVI via NormalDifference()-functie. Vul de '?' in var ndvi = S2_Gent_Lente19 . normalizedDifference ([ '?' , '?' ]). rename ( 'NDVI' ); Map . addLayer ( ndvi ,{}, 'ndvi_lente_2019' ) //Zonder visualisatieparametes Een ndvi wordt meestal afgebeeld met een kleurenschema, zoals onderstaand voorbeeld: // Met visualisatie var ndviParams = { min : - 1 , max : 1 , palette : [ 'red' , 'yellow' , 'darkgreen' ]}; Map . addLayer ( ndvi , ndviParams , 'ndvi_2019_vis' ); Oefening: Connecteer de ndvi-waarden met de gepaste landbedekkingsklasse. NDVI waarde Landbedekking (Lente) Negative values (< 0) rocks, bare soil, clouds Small values (0.1 or less) shrubs and meadows Moderate values (0.2 to 0.3) temperate and tropical forests Large values (0.6 to 0.8) (clouds,) water and snow Antwoord NDVI waarde Landbedekking (Lente) Negative values (< 0) clouds, water and snow Small values (0.1 or less) rocks and bare soil Moderate values (0.2 to 0.3) shrubs and meadows Large values (0.6 to 0.8) temperate and tropical forests","title":"NDVI"},{"location":"P5/P5-Spectral_indices.html#band-math-bandbewerkingen","text":"Bandbewerkingen kunnen worden gebruikt om een nieuw beeld aan te maken van de reeds bestaande banden. Het berekenen van indices zoals de NDVI, is al een treffend voorbeeld hiervan. Andere mogelijkheden zijn ratio\u2019s, het verschil van 2 beelden op 2 verschillende tijdstippen om mogelijke veranderingen visueel te benadrukken, \u2026 Er zijn 2 manieren om in Earth Engine een bewerking uit te voeren.","title":"Band Math (bandbewerkingen)"},{"location":"P5/P5-Spectral_indices.html#bewerkingen-via-operatoren","text":"De basisoperators maken gebruik van 2 inputs: ofwel 2 beelden, ofwel 1 beeld en 1 constante. De bewerkingen worden steeds per pixel en per band uitgevoerd. Voorbeeld van operatoren zijn add() , subtract() en divide() . //NDVI berekenen aan de hand van bandwerkingen met operatoren // Lange uitwerking: noodzakelijke banden eerst selecteren en onderbrengen in een nieuwe variabele var nir = S2_Gent_Lente19 . select ( 'B8' ); var red = S2_Gent_Lente19 . select ( 'B4' ); var ndvi2 = nir . subtract ( red ). divide ( nir . add ( red )). rename ( 'NDVI' ); Map . addLayer ( ndvi2 , ndviParams , 'ndvi via operatoren' ); Het resultaat is logischerwijs identiek als de voorgaande ndvi-berekening.","title":"Bewerkingen via operatoren"},{"location":"P5/P5-Spectral_indices.html#bewerkingen-via-expressies","text":"Het spreekt voor zich dat bovenstaande methode voor complex wiskundige bewerkingen niet handig is. Voor dergelijke bewerkingen wordt aangeraden om gebruik te maken van image.expression() , gezien de inputvariabelen hier afzonderlijk worden aangegeven, waardoor de bewerking gemakkelijker wordt weergegeven en het coderen zo vereenvoudigd wordt. De expressie aanvaardt tevens ook constanten. Variabelen die binnen de expressie worden gebruikt, moeten steeds worden aangegeven, zoals in onderstaande NDVI-berekening; //NDVI aan de hand van een expressie var ndvi3 = SS2_Gent_Lente19 . expression ( '(NIR - RED)/(NIR + RED)' , { 'NIR' : S2_Gent_Lente19 . select ( 'B8' ), 'RED' : S2_Gent_Lente19 . select ( 'B4' ) }); Ook hier is het resultaat hetzelfde als de vorige ndvi-berekeningen. Gebruikte operators binnen expressies Onderstaande tabel geeft de binnen de expressies gehanteerde operators weer (bron: Earth Engine guide )","title":"Bewerkingen via expressies"},{"location":"P5/P5-Spectral_indices.html#andere-indices","text":"Naast de NDVI bestaan er nog een heleboel andere indices, elk met een eigen toepassing.","title":"Andere indices"},{"location":"P5/P5-Spectral_indices.html#de-normalized-difference-water-index-ndwi","text":"Er bestaan 2 indices met de naam 'NDWI', beiden gerelateerd aan water: De NDWI ontwikkeld door Gao (1996) , als index voor het watergehalte van vegetatie. De Index is gebaseerd op de NIR (gevoelig voor vegetatie) en SWIR (gevoelig voor water) banden: NDWI = { NIR - SWIR \\over NIR + SWIR}. De NDWI ontwikkeld door McFeeters (1996) , als index voor het verscherpen van verschillen in waterlichamen; NDWI = { GREEN - NIR \\over GREEN + NIR}. Opdracht NDWI Test beide NDWI-indices uit op het Sentinel-beeld van de Gentse Haven en omstreken. Bekijk de verschillen. Kijk hiervoor zeker naar naburige natuurgebieden en waterplassen.","title":"De Normalized Difference Water Index (NDWI)"},{"location":"P5/P5-Spectral_indices.html#opdrachten","text":"","title":"Opdrachten"},{"location":"P5/P5-Spectral_indices.html#ndvi-voor-elk-seizoen","text":"Maak een wolkenvrije beeldencollectie aan (via 30%-'CLOUDY_PIXEL_PERCENTAGE'-filter + een cloudmask toepassen) aan van de regio Durbuy binnen volgende periodes. Gebruik onderstaande Cloudmask-functie: function maskS2clouds ( image ) { var qa = image . select ( 'QA60' ); // Bits 10 and 11 are clouds and cirrus, respectively. var cloudBitMask = 1 << 10 ; var cirrusBitMask = 1 << 11 ; // Both flags should be set to zero, indicating clear conditions. var mask = qa . bitwiseAnd ( cloudBitMask ). eq ( 0 ) . and ( qa . bitwiseAnd ( cirrusBitMask ). eq ( 0 )); return image . updateMask ( mask ); } 2. Maak een functie aan om de NDVI te berekenen. Laat de functie dan los op de Imagecollectie via .map() . Maak aan de hand van de collectie 3 beelden aan met een median() -reducer, binnen volgende periodes: A. Jan-Februari (Winter) B. April-Mei (Lente) C. Juli-Augustus (Zomer) Visualiseer voor elk seizoen een Normale Kleurencomposiet en een NDVI-beeld. Gebruik onderstaande visualisatieparameters bij het plotten: //Visualisatieparameters instellen var NormaleKleuren = { min : 0 , max : 1500 , bands : [ 'B4' , 'B3' , 'B2' ], }; var ndviParams = { min : 0 , max : 1 , bands : [ 'NDVI' ], palette : [ 'red' , 'yellow' , 'darkgreen' ] };","title":"NDVI voor elk seizoen"},{"location":"P5/P5-Spectral_indices.html#extra-oef-2-de-enhanced-vegetation-index-evi","text":"De EVI is gelijkaardig aan de NDVI daar het gebruikt wordt om de aanwezigheid (of \u2018greenness\u2019) van vegetatie a.d.h.v. satellietbeelden te kwantificeren. Het werd ontwikkeld om aan enkele \u201climitaties\u201d van de ndvi te voldoen: EVI is gevoeliger voor gebieden met hogere biomassa EVI reduceert de invloed van de atmosferische condities EVI corrigeert de \u2018canopy background noise\u2019 , die bij NDVI voorkomt De EVI wordt berekend als volgt: EVI = G * {NIR - R \\over NIR + C1 * RED \u2013 C2*BLUE + L}. (waarbij G : een versterkende constante, C1,C2 co\u00ebfficienten en L een \u2018canopy background adjusment factor\u2019 ) Voor Sentinel 2, wordt deze formule: EVI_{S2} = 2.5 * {B8 - B4 \\over B8 + 6 * B4 \u2013 7.5*B2 + 1}.","title":"EXTRA OEF 2-  De Enhanced Vegetation Index (EVI):"},{"location":"P5/P5-Spectral_indices.html#extra-toevoegen-van-een-legende","text":"Om een overzichtelijke legende toe te voegen aan je kaart, kun je onderstaande code gebruiken. Hiermee voeg je een legendepaneel toe voor continue ndvi-data. //------------------------- /* LEGENDE TOEVOEGEN */ //------------------------- // set position of panel var legend = ui . Panel ({ style : { position : 'bottom-left' , padding : '8px 15px' } }); // Create legend title var legendTitle = ui . Label ({ value : 'ndvi' , style : { fontWeight : 'bold' , fontSize : '18px' , margin : '0 0 4px 0' , padding : '0' } }); // Add the title to the panel legend . add ( legendTitle ); // create the legend image var lon = ee . Image . pixelLonLat (). select ( 'latitude' ); var gradient = lon . multiply (( ndviParams . max - ndviParams . min ) / 100.0 ). add ( ndviParams . min ); var legendImage = gradient . visualize ( ndviParams ); // create text on top of legend var panel = ui . Panel ({ widgets : [ ui . Label ( ndviParams [ 'max' ]) ], }); legend . add ( panel ); // create thumbnail from the image var thumbnail = ui . Thumbnail ({ image : legendImage , params : { bbox : '0,0,10,100' , dimensions : '10x200' }, style : { padding : '1px' , position : 'bottom-center' } }); // add the thumbnail to the legend legend . add ( thumbnail ); // create text on top of legend var panel = ui . Panel ({ widgets : [ ui . Label ( ndviParams [ 'min' ]) ], }); legend . add ( panel ); Map . add ( legend );","title":"EXTRA: Toevoegen van een legende"},{"location":"P5/P5-Texture.html","text":"Textuuranalyse Beeldtextuur kan worden gedefinieerd als \u2018de set van metrieken die berekend worden om bepaalde waargenomen textuureigenschappen van het beeld te kwantificeren\u2019 . Het geeft informatie over de spatiale verspreiding van kleuren of intensiteiten binnen het beeld of een bepaalde regio. De spectrale reflectie van wolken en ijs kan bijvoorbeeld zeer gelijkend zijn, maar de textuur zeer verschillend. Textuur toevoegen als een extra input-band kan dus helpen bij het optimaliseren van een beeldclassificatie. Textuur wordt steeds berekend binnen een bepaalde zone, ook wel neighborhood genoemd. In volgende paragraaf, zullen we enkele textuur indices berekenen. We keren hiervoor even terug naar ons satellietbeeld uit Bel\u00e9m, gezien dit beeld geschikt is ter illustratie van textuur. Hier nog even de code om tot het beeld te komen: //Inladen van het gekende Bel\u00e9m Sentinel-2 beeld var S2_Belem = ee . Image ( 'COPERNICUS/S2_SR/20200808T134219_20200808T134214_T22MGD' ) // Zoom in de Map-view in naar het beeld, met Zoom-factor 9 Map . centerObject ( S2_Belem , 9 ); Map . addLayer ( S2_Belem , { min : 0 , max : 3000 , bands : [ 'B4' , 'B3' , 'B2' ]}); Standaard deviatie De Standaard Deviatie (SD) berekent de spreiding van de pixelwaarde-distributie binnen de neighborhood. //1) Standaard deviatie // Compute standard deviation (SD) as texture van B8 var stdev = S2_Belem . select ( 'B8' ). reduceNeighborhood ({ reducer : ee . Reducer . stdDev (), kernel : ee . Kernel . circle ( 7 ), }); Map . addLayer ( stdev , { min : 0 , max : 2000 }, 'SD of NDVI' ); Grey Level Co-occurence matrix Voor het beschrijven van de textuur wordt gebruik gemaakt van de grey level co-occurence matrix (GLCM) van Haralick et al. (1973). Het is een matrix dat weergeeft hoeveel verschillende combinaties van pixelgrijswaarden voorkomen in een bepaalde neighborhood . Aan de hand van de GLCM kunnen vervolgens verschillende textuurattributen berekend worden om de textuur te beschrijven. Entropie Een eerste voorbeeld is de entropie. De entropie van een beeld vertaalt de randomness van de intensiteit naar een index. Het kan worden gezien als een maat voor \u2018pixeldiversiteit\u2019 binnen een bepaalde zone ( neighborhood ). In dit voorbeeld wordt een kernel aangemaakt met radius 7m, waardoor de textuurberekening dus steeds binnen een radius van 7m wordt berekend. Gezien een entropy-berekening enkel kan worden uitgevoerd op discrete waarden, dienen we het pixeltype eerst om te zetten naar een integer. // Compute the gray-level co-occurrence matrix (GLCM), get contrast. var glcm = S2_Belem . select ( 'B8' ). glcmTexture ({ size : 4 }); var contrast = glcm . select ( 'B8_contrast' ); //Mappen van contrast: speel met de min, max waarden (via stretching) Map . addLayer ( contrast , {}, 'contrast' ); var variance = glcm . select ( 'B8_var' ) Map . addLayer ( variance , {}, 'variance' ); var ent = glcm . select ( 'B8_ent' ); Map . addLayer ( ent , {}, 'Entropy' ); GLCM-textuur in Earth Engine Je merkt wellicht dat de textuurafbeelding van verschillende textuurmaten uit de GLCM varieert naarmate je in- en uitzoomt. Dit is ligt aan het feit dat Earth Engine dit steeds per 'view window' uitrekend, waardoor de resultaten zo verschillend lijken. Echter, als je het beeld exporteert uit Earth Engine en bijvoorbeeld in SNAP opent, bekom je wel een visueel begrijpbaar resultaat. De berekende banden kunnen in Earth Engine echter wel verder gebruikt worden voor classificatie. EXTRA: Export-script Hieronder kun je een voorbeeldscriptje vinden om een raster naar je Google Drive te exporteren. Na een 10-tal minuten kun je dit terug vinden op je persoonlijke Google Drive en downloaden naar je desktop. ```javascript Export.image.toDrive({ image: entropy, description: 'B8_Entropy', scale: 10, //RESOLUTIE folder: 'Sentinel_2_export', maxPixels: 1e12 //Vergroot de exportcapaciteit });","title":"Textuuranalyse"},{"location":"P5/P5-Texture.html#textuuranalyse","text":"Beeldtextuur kan worden gedefinieerd als \u2018de set van metrieken die berekend worden om bepaalde waargenomen textuureigenschappen van het beeld te kwantificeren\u2019 . Het geeft informatie over de spatiale verspreiding van kleuren of intensiteiten binnen het beeld of een bepaalde regio. De spectrale reflectie van wolken en ijs kan bijvoorbeeld zeer gelijkend zijn, maar de textuur zeer verschillend. Textuur toevoegen als een extra input-band kan dus helpen bij het optimaliseren van een beeldclassificatie. Textuur wordt steeds berekend binnen een bepaalde zone, ook wel neighborhood genoemd. In volgende paragraaf, zullen we enkele textuur indices berekenen. We keren hiervoor even terug naar ons satellietbeeld uit Bel\u00e9m, gezien dit beeld geschikt is ter illustratie van textuur. Hier nog even de code om tot het beeld te komen: //Inladen van het gekende Bel\u00e9m Sentinel-2 beeld var S2_Belem = ee . Image ( 'COPERNICUS/S2_SR/20200808T134219_20200808T134214_T22MGD' ) // Zoom in de Map-view in naar het beeld, met Zoom-factor 9 Map . centerObject ( S2_Belem , 9 ); Map . addLayer ( S2_Belem , { min : 0 , max : 3000 , bands : [ 'B4' , 'B3' , 'B2' ]});","title":"Textuuranalyse"},{"location":"P5/P5-Texture.html#standaard-deviatie","text":"De Standaard Deviatie (SD) berekent de spreiding van de pixelwaarde-distributie binnen de neighborhood. //1) Standaard deviatie // Compute standard deviation (SD) as texture van B8 var stdev = S2_Belem . select ( 'B8' ). reduceNeighborhood ({ reducer : ee . Reducer . stdDev (), kernel : ee . Kernel . circle ( 7 ), }); Map . addLayer ( stdev , { min : 0 , max : 2000 }, 'SD of NDVI' );","title":"Standaard deviatie"},{"location":"P5/P5-Texture.html#grey-level-co-occurence-matrix","text":"Voor het beschrijven van de textuur wordt gebruik gemaakt van de grey level co-occurence matrix (GLCM) van Haralick et al. (1973). Het is een matrix dat weergeeft hoeveel verschillende combinaties van pixelgrijswaarden voorkomen in een bepaalde neighborhood . Aan de hand van de GLCM kunnen vervolgens verschillende textuurattributen berekend worden om de textuur te beschrijven.","title":"Grey Level Co-occurence matrix"},{"location":"P5/P5-Texture.html#entropie","text":"Een eerste voorbeeld is de entropie. De entropie van een beeld vertaalt de randomness van de intensiteit naar een index. Het kan worden gezien als een maat voor \u2018pixeldiversiteit\u2019 binnen een bepaalde zone ( neighborhood ). In dit voorbeeld wordt een kernel aangemaakt met radius 7m, waardoor de textuurberekening dus steeds binnen een radius van 7m wordt berekend. Gezien een entropy-berekening enkel kan worden uitgevoerd op discrete waarden, dienen we het pixeltype eerst om te zetten naar een integer. // Compute the gray-level co-occurrence matrix (GLCM), get contrast. var glcm = S2_Belem . select ( 'B8' ). glcmTexture ({ size : 4 }); var contrast = glcm . select ( 'B8_contrast' ); //Mappen van contrast: speel met de min, max waarden (via stretching) Map . addLayer ( contrast , {}, 'contrast' ); var variance = glcm . select ( 'B8_var' ) Map . addLayer ( variance , {}, 'variance' ); var ent = glcm . select ( 'B8_ent' ); Map . addLayer ( ent , {}, 'Entropy' ); GLCM-textuur in Earth Engine Je merkt wellicht dat de textuurafbeelding van verschillende textuurmaten uit de GLCM varieert naarmate je in- en uitzoomt. Dit is ligt aan het feit dat Earth Engine dit steeds per 'view window' uitrekend, waardoor de resultaten zo verschillend lijken. Echter, als je het beeld exporteert uit Earth Engine en bijvoorbeeld in SNAP opent, bekom je wel een visueel begrijpbaar resultaat. De berekende banden kunnen in Earth Engine echter wel verder gebruikt worden voor classificatie.","title":"Entropie"},{"location":"P5/P5-Texture.html#extra-export-script","text":"Hieronder kun je een voorbeeldscriptje vinden om een raster naar je Google Drive te exporteren. Na een 10-tal minuten kun je dit terug vinden op je persoonlijke Google Drive en downloaden naar je desktop. ```javascript Export.image.toDrive({ image: entropy, description: 'B8_Entropy', scale: 10, //RESOLUTIE folder: 'Sentinel_2_export', maxPixels: 1e12 //Vergroot de exportcapaciteit });","title":"EXTRA: Export-script"}]}